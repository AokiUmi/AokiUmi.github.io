<!DOCTYPE HTML>
<html>

<head><meta name="generator" content="Hexo 3.9.0">
	<link rel="bookmark" type="image/x-icon" href="img/love.jpg">
	<link rel="shortcut icon" href="img/love.jpg">
	
			    <title>
    Aoki_Umi
    </title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <link rel="stylesheet" href="/css/mic_main.css">
    <link rel="stylesheet" href="/css/dropdownMenu.css">
 <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <span id="busuanzi_container_site_pv">��վ�ܷ�����<span id="busuanzi_value_site_pv"></span>��</span>
    <meta name="keywords" content="Aoki_Umi">
    
    	<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	 
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css">
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('/img/bg.jpg') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script async type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.scrollex.min.js"></script>
    <script src="/js/jquery.scrolly.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
<link rel="alternate" href="atom.xml" title="Aoki_Umi" type="application/atom+xml">
</head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<script>hljs.initHighlightingOnLoad();</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/go.min.js"></script>
<link rel="stylesheet" href="/css/prism_coy.css">
<link rel="stylesheet" href="/css/typo.css">
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="/" class="logo">AOKI_UMI</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special">
            <ul class="menu links">
			<!-- Homepage  主页  --> 
			<li>
	            <a href="/" rel="nofollow">HOME</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <li class="active">
	            <a href="#s1">CATEGORIES</a>
	                    <ul class="submenu">
	                        <li>
	                        <a class="category-link" href="../categories/CS/">CS</a></li><li><a class="category-link" href="../categories/CS/AI/">AI</a></li><li><a class="category-link" href="../categories/CS/ALGORITHM/">ALGORITHM</a></li><li><a class="category-link" href="../categories/CS/ASSEMBLY-LANGUAGE/">ASSEMBLY_LANGUAGE</a></li><li><a class="category-link" href="../categories/CS/C-C/">C&C++</a></li><li><a class="category-link" href="../categories/CS/CA/">CA</a></li><li><a class="category-link" href="../categories/CS/DESIGN/">DESIGN</a></li><li><a class="category-link" href="../categories/CS/PYTHON/">PYTHON</a></li><li><a class="category-link" href="../categories/CS/PYTHON/ALGORITHM/">ALGORITHM</a></li><li><a class="category-link" href="../categories/CS/SIGNAL-PROCESSING/">SIGNAL_PROCESSING</a></li><li><a class="category-link" href="../categories/OI/">OI</a></li><li><a class="category-link" href="../categories/OI/ALGORITHM/">ALGORITHM</a></li><li><a class="category-link" href="../categories/OI/Algorithm/">Algorithm</a></li><li><a class="category-link" href="../categories/OI/Algorithm/Tree/">Tree</a></li><li><a class="category-link" href="../categories/OI/Character-String/">Character String</a></li><li><a class="category-link" href="../categories/OI/Congratulation/">Congratulation</a></li><li><a class="category-link" href="../categories/OI/Contest/">Contest</a></li><li><a class="category-link" href="../categories/OI/DATA-STRUCTURE/">DATA STRUCTURE</a></li><li><a class="category-link" href="../categories/OI/DP/">DP</a></li><li><a class="category-link" href="../categories/OI/GRAPH-THERY/">GRAPH THERY</a></li><li><a class="category-link" href="../categories/OI/Graph-Theory/">Graph Theory</a></li><li><a class="category-link" href="../categories/OI/Maths/">Maths</a></li><li><a class="category-link" href="../categories/OI/Search/">Search</a></li><li><a class="category-link" href="../categories/OI/Simulation/">Simulation</a></li><li><a class="category-link" href="../categories/STUDY/">STUDY</a>
	                    </li></ul>
	        </li>
	        
	        <!-- archives  归档   --> 
	        
	        <li class="active">
	            <a href="#s1">ARCHIVES</a>
	                    <ul class="submenu">
	                        <li>
	                        <a class="archive-link" href="../archives/2023/12/">December 2023</a></li><li><a class="archive-link" href="../archives/2023/10/">October 2023</a></li><li><a class="archive-link" href="../archives/2023/09/">September 2023</a></li><li><a class="archive-link" href="../archives/2022/10/">October 2022</a></li><li><a class="archive-link" href="../archives/2022/06/">June 2022</a></li><li><a class="archive-link" href="../archives/2022/01/">January 2022</a></li><li><a class="archive-link" href="../archives/2021/11/">November 2021</a></li><li><a class="archive-link" href="../archives/2021/04/">April 2021</a></li><li><a class="archive-link" href="../archives/2021/01/">January 2021</a></li><li><a class="archive-link" href="../archives/2020/11/">November 2020</a></li><li><a class="archive-link" href="../archives/2020/10/">October 2020</a></li><li><a class="archive-link" href="../archives/2020/08/">August 2020</a></li><li><a class="archive-link" href="../archives/2020/06/">June 2020</a></li><li><a class="archive-link" href="../archives/2020/05/">May 2020</a></li><li><a class="archive-link" href="../archives/2020/04/">April 2020</a></li><li><a class="archive-link" href="../archives/2020/02/">February 2020</a></li><li><a class="archive-link" href="../archives/2018/11/">November 2018</a></li><li><a class="archive-link" href="../archives/2018/10/">October 2018</a></li><li><a class="archive-link" href="../archives/2018/09/">September 2018</a></li><li><a class="archive-link" href="../archives/2018/08/">August 2018</a></li><li><a class="archive-link" href="../archives/2018/07/">July 2018</a></li><li><a class="archive-link" href="../archives/2018/05/">May 2018</a></li><li><a class="archive-link" href="../archives/2018/04/">April 2018</a></li><li><a class="archive-link" href="../archives/2018/03/">March 2018</a></li><li><a class="archive-link" href="../archives/2018/01/">January 2018</a>
	                    </li></ul>
	        </li>
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/about/" title="ABOUT">
		                ABOUT
		            </a>
		        </li>
		        
		        <li>
		            <a href="/group/" title="FRIENDS">
		                FRIENDS
		            </a>
		        </li>
		        
		        <li>
		            <a href="/gallery/" title="GALLERY">
		                GALLERY
		            </a>
		        </li>
		        
		        <li>
		            <a href="/tag/" title="TAG">
		                TAG
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
                    
                    <li>
                        <a title="github" href="https://github.com/AokiUmi" target="_blank" rel="noopener">
                            <i class="icon fa fa-github"></i>
                        </a>
                    </li>
                    
                    <li>
                        <a title="500px" href="http://500px.com" target="_blank" rel="noopener">
                            <i class="icon fa fa-500px"></i>
                        </a>
                    </li>
                    
			</ul>
</nav>

        <div id="main">
            <div class="post_page_title_img" style="height: 25rem;background-image: url(/images/0051.jpg);background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;">
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2>CS320学习笔记</h2></a>
         
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">

                <h1 id="Reproducibility"><a href="#Reproducibility" class="headerlink" title="Reproducibility"></a>Reproducibility</h1><p><strong>reproducibility</strong>: others can run our analysis code and get same results</p>
<p>Each process owns address space (one huge list)</p>
<p>Multiple lists start at different address in address space; normally, append is faster than pop, since pop need to move all next items forward 4 bytes.</p>
<p>Use ASCII to store strings, use specific <strong>ISA to store codes</strong>.</p>
<p>CPU interact with memory: </p>
<ul>
<li><p>keep track of what instruction we’re on</p>
</li>
<li><p>understand instruction codes</p>
</li>
</ul>
<p>A CPU can <strong>only run programs</strong> that <strong>use instructions it understands</strong>.</p>
<p><strong>CPU:</strong> chip that executes instructions, tracks position in code</p>
<p>process: a running program</p>
<h2 id="Interpreters"><a href="#Interpreters" class="headerlink" title="Interpreters"></a>Interpreters</h2><p>make it easier to run the same code on different machines</p>
<p>A compiler is another tool for running the same code on different CPUs</p>
<p>Interpreter <strong>translates Python code</strong> into machine code for a give CPU instruction set, </p>
<p>hiding details about the <strong>CPU’s instruction</strong> set from the programmer.</p>
<p>Translate Python code to CPU instructions</p>
<h2 id="OS"><a href="#OS" class="headerlink" title="OS"></a>OS</h2><p>OS jobs: Allocate and Abstract Resources, software that <strong>manage computer hardware and software resources</strong>, providing a stable and consistent interface for users and applications to interact with the computer system.</p>
<p>Only one process can run on CPU at a time  (or a few things if the CPU has multiple “cores”)</p>
<ul>
<li><p>process management</p>
</li>
<li><p>memory management</p>
</li>
</ul>
<p>The Python interpreter mostly lets you [Python Programmer] ignore the CPU you run on.</p>
<p>But you still need to work a bit to “fit” the code to the OS.</p>
<h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><p>version control system tools</p>
<p>features:</p>
<ul>
<li><p>it allows people to create snapshots of their work even while offline</p>
</li>
<li><p>it allows programmers to document the changes they made</p>
</li>
<li><p>it allows multiple version of history in the same repo</p>
</li>
<li><p>it sometimes automatically resolves conflicts</p>
</li>
<li><p><del>it automatically creates commits at regular intervals, it automatically creates commits when files change</del></p>
</li>
</ul>
<p><strong>git branch:</strong> list your branches. a * will appear next to the currently active branch</p>
<p><strong>git checkout:</strong> switch to another branch and check it out into your working directory</p>
<p><strong>HEAD:</strong> wherever you currently are (only one of these) , * means where your HEAD is</p>
<p><strong>tag:</strong> label tied to a specific commit number  </p>
<p><strong>branch:</strong> label tied to end of chain (moves upon new commits</p>
<p><strong>commit:</strong> a snapshot of files at a point in time</p>
<p><strong>merge:</strong> to combine changes on another branch into the current branch  </p>
<p><strong>conflict:</strong> differences that cannot automatically be merged</p>
<p><strong>headless:</strong> HEAD does not point to any branch</p>
<p><strong>Detached HEAD:</strong> refers to a situation where the <strong>HEAD</strong> pointer (which usually points to a branch reference) <strong>directly points to a specific commit</strong>, <strong>rather than pointing to the latest commit of a branch</strong>. </p>
<p>In simpler terms, when you’re working in a normal branch (say, “master” or “main”), the HEAD points to the name of that branch, and that branch name points to the latest commit. </p>
<p>Any new commits you make will advance the branch to point to the newer commit, and HEAD follows along because it’s pointing to the branch name.</p>
<p><img src="/2023/10/07/CS320学习笔记/1.png" alt></p>
<p>As you can see, HEAD points to the controller branch, which points to the last commit. Everything looks perfect. After running <strong>git checkout 87ec91d,</strong> the repo looks like this:</p>
<p><img src="/2023/10/07/CS320学习笔记/2.png" alt></p>
<p>This is the detached HEAD state; HEAD is pointing directly to a commit instead of a branch.</p>
<p>git demonstration</p>
<p><img src="/2023/10/07/CS320学习笔记/3.png" alt></p>
<p><strong>fast forwarding:</strong> If master has not diverged, instead of creating a new commit, git will then simply point master to the latest commit of the feature branch. This is a “fast forward”.</p>
<p><img src="/2023/10/07/CS320学习笔记/16.png" alt></p>
<p><img src="/2023/10/07/CS320学习笔记/15.png" alt></p>
<p>如果合并的两个branch在一条线上，git checkout 前面的branch，merge后面的，就会触发fast forwarding</p>
<p><code>--no--ff</code> means 不用fast forwarding</p>
<p><img src="/2023/10/07/CS320学习笔记/17.png" alt></p>
<p>If you’re on branch <strong>x</strong> and run ‘git merge y’, then you will point to new branch named <strong>x</strong></p>
<p>When making a git commit, the head is recommend to point to <strong>branch</strong>, otherwise may cause detached HEAD problem</p>
<p><strong>checkout:</strong></p>
<ul>
<li><p>output is <strong>bytes</strong>, not string</p>
</li>
<li><p><code>checkout([&quot;git&quot;,&quot;commit&quot;,cwd=&quot;directory_name&quot;)</code></p>
</li>
</ul>
<h1 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h1><p>Things that affect performance:</p>
<ul>
<li>speed of the computer (CPU, etc)  </li>
<li>speed of Python (quality+efficiency of interpretation)  </li>
<li>algorithm: strategy for solving the problem  </li>
<li>input size: how much data do we have?</li>
</ul>
<p>when analyze complexity, only care about big inputs</p>
<p><img src="/2023/10/07/CS320学习笔记/4.png" alt></p>
<p>A step is any unit of work with boudned execution time. (“bounded” does not mean “fixed”)</p>
<h2 id="Big-O"><a href="#Big-O" class="headerlink" title="Big O"></a>Big O</h2><p>If $f(N) \leq C * g(N)$, then $f(N) \in O(g(N))$</p>
<p><strong>Common complexity for list operation:</strong></p>
<ul>
<li><p>$O(1)$: <code>len(L),L[-1],L[-10],L.append(x),L.pop(-1)</code></p>
</li>
<li><p>$O(N)$: <code>L.insert(0,x),L.pop(0),max(L),min(L),sum(L),L2.extend(L1),found x in L</code></p>
</li>
</ul>
<p><strong>Special case:</strong></p>
<p>for <code>deque</code>(双端队列): $O(1)$<code>deque.popleft(0),deque.pop()</code></p>
<p>for <code>heapq</code>(小根堆): $O(1ogN)$ <code>heapq.heappop(), heapq.heappush(x)</code></p>
<p>$O(N)$ <code>heapq.heapify(L)</code></p>
<h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><p>看图说话</p>
<p><img src="/2023/10/07/CS320学习笔记/5.png" alt></p>
<p><img src="/2023/10/07/CS320学习笔记/6.png" alt></p>
<p><img src="/2023/10/07/CS320学习笔记/7.png" alt></p>
<h1 id="Object-Oriented-Programming"><a href="#Object-Oriented-Programming" class="headerlink" title="Object Oriented Programming"></a>Object Oriented Programming</h1><p><img src="/2023/10/07/CS320学习笔记/8.png" alt></p>
<p><code>Dog.speak(fido,5)</code>is NOT an example of type-based dispatch</p>
<p><code>fido.speak(5)</code>is preferred</p>
<p><code>def __init__(dog,name,age):</code> <code>self</code> is better than <code>dog</code> for the receiver parameter</p>
<h2 id="Special-Methods"><a href="#Special-Methods" class="headerlink" title="Special Methods"></a>Special Methods</h2><p>Not all <code>__some__</code> is special methods</p>
<p><strong>implicitly</strong> called</p>
<h3 id="str-vs-repr"><a href="#str-vs-repr" class="headerlink" title="__str__ vs__repr__"></a><code>__str__</code> vs<code>__repr__</code></h3><p> <code>__str__</code>, <code>__repr__</code>, control how an object looks when we print it or see it in <code>Out[N]</code> <code>print(),str()</code>方法会调用到<code>__str__</code>方法，<code>print(),str(),repr()</code>方法会调用<code>__repr__</code>方法。从下面的例子可以看出，当两个方法同时定义时，Python会优先搜索并调用<code>__str__</code>方法。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">class</span> <span class="token class-name">Str</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token keyword">def</span> <span class="token function">__str__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>         <span class="token keyword">return</span> <span class="token string">"__str__ called"</span>    
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>         <span class="token keyword">return</span> <span class="token string">"__repr__ called"</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> 
<span class="token operator">>></span><span class="token operator">></span> s <span class="token operator">=</span> Str<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>
__str__ called
<span class="token operator">>></span><span class="token operator">></span> repr<span class="token punctuation">(</span>s<span class="token punctuation">)</span>
<span class="token string">'__repr__ called'</span>
<span class="token operator">>></span><span class="token operator">></span> str<span class="token punctuation">(</span>s<span class="token punctuation">)</span>
<span class="token string">'__str__ called'</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong><code>__repr__</code></strong></p>
<ul>
<li>The <code>__repr__</code> method is used to define the “official” string representation of an object. It is used by the <code>repr()</code> built-in function and by backticks (<code>`</code>) in Python 2.x.</li>
<li>The string returned by <code>__repr__</code> should be a valid Python expression that, when evaluated, would create an object with the same state as the original object. In other words, it should be unambiguous and precise.</li>
<li>This method is <strong>primarily used for debugging and development purposes</strong>.</li>
</ul>
<p><strong><code>__str__</code>:</strong></p>
<ul>
<li>The <code>__str__</code> method is used to define the <strong>“informal” or “user-friendly”</strong> string representation of an object. It is used by the <code>str()</code> built-in function and by the <code>print()</code> function.</li>
<li>The string returned by <code>__str__</code> should be readable and understandable to users.</li>
<li>If <code>__str__</code> is not defined, the <code>__repr__</code> method will be used as a fallback.</li>
</ul>
<p>In summary, <code>__repr__</code> is more for <strong>developers</strong>, providing <strong>a detailed and unambiguous representation*</strong> of an object, while <code>__str__</code> is for <strong>users</strong>, presenting a <strong>more user-friendly and readable representation</strong> of the object. It’s common to implement <code>__repr__</code> and optionally <code>__str__</code> for your custom classes to enhance their debuggability and usability.</p>
<p><code>__repr_html__</code>, generate HTML to create more visual representaitons of objects in Jupyter.</p>
<p><code>__eq__</code>, <code>__ne__</code>, <code>__lt__</code>, <code>__ge__</code>,<code>__le__</code>, <code>__ge__</code>,define how ==, !=, &lt;, &gt;, &lt;=, &gt;= behaves for two different objects, for <code>sorted</code>, must implement <code>__lt__</code></p>
<p><code>__len__</code>, <code>__getitem__</code>, build our own sequences that we <code>index</code>, <code>slice</code>, and <code>loop</code> over. </p>
<p><code>__enter__</code>, <code>__exit__</code>, context managers, (like automatically close file)</p>
<p>with语句，先调用<code>__enter__</code>在<code>__init__</code>之后，在with结束后调用<code>__exit__</code></p>
<p>positional arguments includes <code>self</code></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">getgrade</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> score<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" This function computes a grade given a score"""</span>
    <span class="token keyword">if</span> score <span class="token operator">></span> <span class="token number">80</span><span class="token punctuation">:</span>
        grade <span class="token operator">=</span> <span class="token string">'A'</span>y
    <span class="token keyword">elif</span> <span class="token number">80</span> <span class="token operator">></span> score <span class="token operator">></span> <span class="token number">70</span><span class="token punctuation">:</span>
        grade <span class="token operator">=</span> <span class="token string">'B'</span>
    <span class="token keyword">elif</span> <span class="token number">70</span> <span class="token operator">></span> score <span class="token operator">></span> <span class="token number">60</span><span class="token punctuation">:</span>
        grade <span class="token operator">=</span> <span class="token string">'C'</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        grade <span class="token operator">=</span> <span class="token string">'D'</span>

    <span class="token keyword">return</span> name <span class="token operator">+</span> <span class="token string">" had grade: "</span> <span class="token operator">+</span> grade 
getgrade<span class="token punctuation">(</span><span class="token string">'prince'</span><span class="token punctuation">,</span> <span class="token number">78</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># To call this function using positional arguments:</span>
getgrade<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'prince'</span><span class="token punctuation">,</span> score<span class="token operator">=</span><span class="token number">78</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># using keyword arguments:  </span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>positional arguments就是不带=，带=就是keyword</p>
<p>Attributes are the individual data items or characteristics associated with an object.</p>
<ul>
<li><p>class attribute </p>
</li>
<li><p>instance attribute</p>
</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyClass</span><span class="token punctuation">:</span>
    class_attribute <span class="token operator">=</span> <span class="token number">42</span>  <span class="token comment" spellcheck="true"># 'class_attribute' is a class attribute</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>value <span class="token operator">=</span> value  <span class="token comment" spellcheck="true"># 'value' is an instance attribute</span>

obj1 <span class="token operator">=</span> MyClass<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>obj1<span class="token punctuation">.</span>value<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Out put 10</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>obj1<span class="token punctuation">.</span>class_attribute<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Output: 42</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Assume <code>Car</code> is one of the child class of <code>Vehicle</code>. Which of the following allows me to call the <code>drive()</code> method defined in the <code>Vehicle</code> class within the <code>Car</code> class? </p>
<ul>
<li><p><code>super().drive()</code></p>
</li>
<li><p><code>Vehicle.drive(self)</code></p>
</li>
</ul>
<p>The X class is a parent of the Y class; both have an <code>__init__</code>method. Both <code>__init__</code> methods are guaranteed to run when a new instance of Y is created, regardless of the code in Y’s <code>__init__</code> method.</p>
<ul>
<li>False</li>
</ul>
<p>htop shows <strong>how much memory is being used</strong></p>
<p>TextIOWrapper is for <strong>converting bytes to str</strong></p>
<p>What is the benefit of reading a CSV inside a .zip file directly from Python, without unzipping it from the command line first?</p>
<ul>
<li>to save storage space </li>
</ul>
<p>What is the benefit of using <code>csv.DictReader</code> instead of <code>pd.read_csv</code> ?</p>
<ul>
<li>save memory space</li>
</ul>
<h1 id="Recursion"><a href="#Recursion" class="headerlink" title="Recursion"></a>Recursion</h1><h2 id="Call-graph"><a href="#Call-graph" class="headerlink" title="Call graph"></a>Call graph</h2><p><img src="/2023/10/07/CS320学习笔记/9.png" alt></p>
<h2 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h2><p>global frames hold all global variables</p>
<p>stack frames <strong>hold local variables</strong></p>
<p>Each function can have <strong>multiple</strong> frames on the stack at a time.</p>
<p><img src="/2023/10/07/CS320学习笔记/10.png" alt></p>
<p><img src="/2023/10/07/CS320学习笔记/11.png" alt></p>
<h1 id="BST"><a href="#BST" class="headerlink" title="BST"></a>BST</h1><p>左儿子比自己小，右儿子比自己大，建树和输入顺序有关系</p>
<p>randomly input 会让树更balanced</p>
<p>insert 复杂度 $O(H)$ 最坏$O(N)$ 最好$O(logN)$ <img src="/2023/10/07/CS320学习笔记/12.png" alt></p>
<h1 id="Search"><a href="#Search" class="headerlink" title="Search"></a>Search</h1><p>DAG : 有向无环图</p>
<p>Strongly connected: 强连通图，考虑direction，所有节点都能相互走到</p>
<p>Weakly connected：弱联通，忽略方向，所有节点都能互相到达</p>
<p>Acyclic：无环</p>
<h2 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a>DFS</h2><p>优先深节点</p>
<p>用stack栈，每次加入节点的孩子，先加大的再小的（保证尾巴先出来的是小的），尾进尾出</p>
<p>对于环，遇到已经加到栈的孩子仍然新加一个相同的</p>
<p>A</p>
<p>H B</p>
<p>H E C</p>
<p>H E D</p>
<p>H E</p>
<p>H G F</p>
<p>H G</p>
<p>H</p>
<p>M I</p>
<p>M L K J</p>
<p>M L</p>
<p>M</p>
<p>A, B, C, D, E, F, G, H, I, J, K, L ,M</p>
<p><img src="/2023/10/07/CS320学习笔记/14.png" alt></p>
<h2 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a>BFS</h2><p>优先更浅的节点</p>
<p>用deque双端队列，每次加入节点的孩子，先加小的再大的，尾进头出</p>
<p>A</p>
<p>B H</p>
<p>H C D G</p>
<p>C D G I</p>
<p>D G I</p>
<p>G I E F</p>
<p>I E F</p>
<p>E F J K</p>
<p>F J K</p>
<p>J K</p>
<p>K</p>
<p>A, B, H, C, D, G, I, E, F, J, K</p>
<p><img src="/2023/10/07/CS320学习笔记/13.png" alt></p>
<h1 id="Selenium"><a href="#Selenium" class="headerlink" title="Selenium"></a>Selenium</h1><h2 id="DOM"><a href="#DOM" class="headerlink" title="DOM"></a>DOM</h2><p>Every web page is a tree.</p>
<p>Elements (nodes of the DOM (document object model) tree) may contain attributes, text, and other elements.</p>
<p><strong>JavaScript</strong> can <strong>directly edit</strong> the DOM tree.</p>
<p>Browser renders (displays) DOM tree, based on original HTML (hyper-text markup language) file and any JavaScript changes.</p>
<p>DAG, weakly connected graph is right. Binary tree is false.</p>
<h2 id="Web-Scraping"><a href="#Web-Scraping" class="headerlink" title="Web Scraping"></a>Web Scraping</h2><p> <code>request</code> can fetch <code>html, js</code>, etc file.</p>
<p><code>Selenium</code> can fetch <code>html, js</code>, etc file, run a js file in browser, and grab HTML version of DOM after JavaScript has modified it.</p>
<h3 id="Finding-Elements-on-Webpages"><a href="#Finding-Elements-on-Webpages" class="headerlink" title="Finding Elements on Webpages"></a>Finding Elements on Webpages</h3><p> <code>WebDriver.get(u)</code> loads the web page with URL (uniform resource locator) <code>u</code></p>
<p><code>WebDriver.find_element(a, b)</code> returns the <strong>first WebElement</strong> which has attribute <code>a</code> being <code>b</code>, and</p>
<p><code>WebDriver.find_elements(a, b)</code> returns a list of WebElements:</p>
<h3 id="Common-Attributes"><a href="#Common-Attributes" class="headerlink" title="Common Attributes"></a>Common Attributes</h3><p><code>WebDriver.find_element(&quot;id&quot;, id)</code> locates the element by its unique ID.<br><code>WebDriver.find_element(&quot;name&quot;, id)</code> locates the element by its names, but multiple elements can have the same name.<br> <code>WebDriver.find_element(&quot;tag name&quot;, id)</code> locates the element by its tag, some of the common tags include:</p>
<table>
<thead>
<tr>
<th>Tag</th>
<th>Element</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>a</code></td>
<td>hyperlink</td>
<td><a href="https://www.w3schools.com/TAGs/" target="_blank" rel="noopener">Link</a></td>
</tr>
<tr>
<td><code>button</code></td>
<td>button</td>
<td>button</td>
</tr>
<tr>
<td><code>code</code></td>
<td>code</td>
<td><code>code</code></td>
</tr>
<tr>
<td><code>div</code> or <code>span</code></td>
<td>section</td>
<td>span</td>
</tr>
<tr>
<td><code>h1</code> to <code>h6</code></td>
<td>headings</td>
<td></td>
</tr>
<tr>
<td><code>img</code> and <code>video</code></td>
<td>image and video</td>
<td></td>
</tr>
<tr>
<td><code>input</code> and <code>textarea</code></td>
<td>text fields</td>
<td></td>
</tr>
<tr>
<td><code>ol</code> or <code>ul</code></td>
<td>ordered or unordered list</td>
<td><code>li</code> is an item</td>
</tr>
<tr>
<td><code>p</code></td>
<td>paragraph</td>
<td></td>
</tr>
<tr>
<td><code>select</code></td>
<td>drop-down list</td>
<td>1/ 2 / 3</td>
</tr>
<tr>
<td><code>table</code></td>
<td>table</td>
<td><code>tr</code> is a row, and <code>td</code> is a cell in the table</td>
</tr>
</tbody>
</table>
<p>Tables can be scraped by <code>find_element(&quot;tag name&quot;, &quot;table&quot;)</code> and iterate over <code>find_elements(&quot;tag name&quot;, &quot;tr&quot;)</code> and <code>find_elements(&quot;tag name&quot;, &quot;td&quot;)</code></p>
<p><code>pandas.read_html</code> can return a list of <code>DataFrame</code>s, one for each table, on the web page.</p>
<p>$j$th cell of first row: <code>element.find_element(&quot;tag name&quot;, &quot;tr&quot;)[i - 1].find_elements(&quot;tag name&quot;, &quot;td&quot;)[j - 1].text</code></p>
<p>$j$th cell of $i$th row: <code>element.find_elements(&quot;tag name&quot;, &quot;tr&quot;)[i - 1].find_elements(&quot;tag name&quot;, &quot;td&quot;)[j - 1].text</code></p>
<h3 id="Screenshot"><a href="#Screenshot" class="headerlink" title="Screenshot"></a>Screenshot</h3><p><code>WebDriver.save_screenshot(&quot;file.png&quot;)</code> saves a screenshot of the web page to a file with name <code>file.png</code>.</p>
<p>Sometimes the screenshot only captures only a part of the page: Firefox has the option to take screenshot of the full page using <code>WebDriver.save_full_screenshot(&quot;file.png&quot;)</code>.</p>
<p>Alternatively, a screenshot of a specific element can be save using <code>WebElement.screenshot(&quot;file.png&quot;)</code>.</p>
<h3 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h3><p><code>WebDriver.find_elements(&quot;tag_name&quot;, &quot;a&quot;)</code> finds all the hyperlinks on the page.</p>
<p>Use <code>url = WebElement.get_attribute(&quot;href&quot;)</code> to get the URL of the hyperlink, then use <code>WebDriver.get(url)</code> to load that page.</p>
<h2 id="Polling"><a href="#Polling" class="headerlink" title="Polling"></a>Polling</h2><p>Use <code>time.sleep(s)</code> to wait <code>s</code> seconds, and use it inside a <code>while</code> loop to wait for an event to happen, before accessing or interacting with the updated elements.</p>
<p>Avoid infinite loops by setting a maximum amount of time to wait.</p>
<p><code>selenium.webdriver.support</code> has implicit and explicit waits, so that the driver keeps polling until a certain condition is met or a certain time has passed</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> selenium <span class="token keyword">import</span> webdriver
<span class="token keyword">from</span> selenium<span class="token punctuation">.</span>webdriver<span class="token punctuation">.</span>common<span class="token punctuation">.</span>by <span class="token keyword">import</span> By
<span class="token keyword">from</span> selenium<span class="token punctuation">.</span>webdriver<span class="token punctuation">.</span>support<span class="token punctuation">.</span>wait <span class="token keyword">import</span> WebDriverWait
<span class="token keyword">from</span> selenium<span class="token punctuation">.</span>webdriver<span class="token punctuation">.</span>support <span class="token keyword">import</span> expected_conditions <span class="token keyword">as</span> EC

driver <span class="token operator">=</span> webdriver<span class="token punctuation">.</span>Firefox<span class="token punctuation">(</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"http://somedomain/url_that_delays_loading"</span><span class="token punctuation">)</span>
<span class="token keyword">try</span><span class="token punctuation">:</span>
    element <span class="token operator">=</span> WebDriverWait<span class="token punctuation">(</span>driver<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>until<span class="token punctuation">(</span>
        EC<span class="token punctuation">.</span>presence_of_element_located<span class="token punctuation">(</span><span class="token punctuation">(</span>By<span class="token punctuation">.</span>ID<span class="token punctuation">,</span> <span class="token string">"myDynamicElement"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token operator">//</span> WebDriver<span class="token punctuation">.</span>find_element<span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">,</span> id<span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
<span class="token keyword">finally</span><span class="token punctuation">:</span>
    driver<span class="token punctuation">.</span>quit<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Interact-with-Elements"><a href="#Interact-with-Elements" class="headerlink" title="Interact with Elements"></a>Interact with Elements</h2><p>Selenium can interact with elements and update the DOM tree.</p>
<p><code>WebElement.send_keys(t)</code> enters text <code>t</code> into the element (<code>input</code> and <code>textarea</code>), (更新input或者textarea的内容)</p>
<p><code>WebElement.clear()</code> clears the text in the element, and <code>WebElement.click()</code> clicks the element (<code>buttons</code>)</p>
<h2 id="Robots-Exclusion-Protocol"><a href="#Robots-Exclusion-Protocol" class="headerlink" title="Robots Exclusion Protocol"></a>Robots Exclusion Protocol</h2><p><code>urllib.robotparser</code> can be used to check whether a website allows scraping</p>
<p><code>RobotFileParser.can_fetch(useragent, url)</code> returns <code>True</code> if the <code>useragent</code> (for example, <code>&quot;*&quot;</code>) is allowed to fetch <code>url</code>.</p>
<h1 id="Advancing-Graph-Search"><a href="#Advancing-Graph-Search" class="headerlink" title="Advancing Graph Search"></a>Advancing Graph Search</h1><h2 id="Infinite-Graph-Search"><a href="#Infinite-Graph-Search" class="headerlink" title="Infinite Graph Search"></a>Infinite Graph Search</h2><p>If the pages are nodes, and links on one page to another page are edges, the digraph formed by pages will possibly have infinite depth and may contain cycles.</p>
<p>To find a specific (goal) page, or to discover reachable pages from the initial page, <strong>breadth first search</strong> should be used (since depth first search may not terminate on trees with infinite depth).</p>
<p>Since there are cycles, <strong>a list of visited pages should be kept</strong>.</p>
<h2 id="Search-Heuristics"><a href="#Search-Heuristics" class="headerlink" title="Search Heuristics"></a>Search Heuristics</h2><p><strong>A search heuristic</strong> is an estimate of <strong>how close</strong> the current node is to the goal node in the search tree.</p>
<p>Before the start of a search, the heuristic functions may not be accurate estimates of the distances from the current node to the goal node.</p>
<p>A heuristic that always underestimates the true distance is called an <strong>admissible heuristic</strong>.</p>
<p>①admissible：$0\leq h(n)\leq h^*(n)$，小于实际n到终点的距离。</p>
<h2 id="Informed-Search"><a href="#Informed-Search" class="headerlink" title="Informed Search"></a>Informed Search</h2><p>Searching the nodes in the order according to the heuristic is called <strong>best first greedy search</strong> (GBS, since BFGS is reserved for the non-linear optimization method, <a href="https://en.wikipedia.org/wiki/Broyden–Fletcher–Goldfarb–Shanno_algorithm" target="_blank" rel="noopener">Link</a>).</p>
<p>贪心：只考虑H最小</p>
<p>Since the heuristic could be incorrect, it might <strong>not find the shortest path to the goal node</strong>.</p>
<p>Searching the nodes in the order according to the current distance from the initial node plus the heuristic is called A search (the name of the search algorithm is “A”)</p>
<p>If the heuristic is admissible, A search is called A* search (A-star search).</p>
<p>For <strong>GBS</strong> search, use a Priority Queue with the priority based on the <strong>heuristic</strong> Only h</p>
<p>For <strong>A search</strong>, use a Priority Queue with the priority based on <strong>current distance plus the heuristic</strong>. h+g</p>
<p>A goal node that is reachable (finite edges away) from the initial node, but the following method cannot find the goal node.Assume the nodes are {G,0,1,2,…} where 0 is the initial node and G is the goal node, and each node has finite number of children.</p>
<p>BFS &amp; A: will find the goal</p>
<p>DFS: 深度优先，会优先最深的 $(0,2)(2,G),(0,1),(1,3),(3,4),(4,5),…$</p>
<p>GBS: 启发函数不好，导致先搜索非goal的子树</p>
<h1 id="Flask"><a href="#Flask" class="headerlink" title="Flask"></a>Flask</h1><p>Flask will be used to create or modify web pages. It can be useful for collecting visitor data when interacting with the web pages and displaying them on the web pages</p>
<p>Flask is a simpler web framework of Django. Django is a more popular package.</p>
<h2 id="Basics"><a href="#Basics" class="headerlink" title="Basics"></a>Basics</h2><p><code>app = flask.Flask(...)</code> to create a web app </p>
<p><a href="mailto:`@app.route" target="_blank" rel="noopener">`@app.route</a>(“/“)` binds a function to the root URL (front page of the website).</p>
<p><a href="mailto:`@app.route" target="_blank" rel="noopener">`@app.route</a>(“/abc”)` binds a function to a specific URL path on the site (one page on the website, or a file).</p>
<p><code>app.run(host=&quot;0.0.0.0&quot;, debug=False, threaded=False)</code> to run the app. <code>host=&quot;0.0.0.0&quot;</code> makes the server externally visible.</p>
<p><code>flask.Response</code>: enables us to create a response object instance</p>
<ul>
<li>Arguments: <code>str</code> representing repsonse, <code>headers</code> dict representing metadata, <code>status</code> representing status code.</li>
<li><code>flask.request.remote_addr</code>: enables us to take action based on the IP address from which we receive the request</li>
<li><code>flask.request.args</code>: enables us to get the arguments passed as part of the URL<ul>
<li>How do we pass arguments?<ul>
<li>at the end of the URL, add a “?”</li>
<li>then separate argument-value pair by “=”</li>
<li>use “&amp;” as delimiter between two argument-value pairs</li>
<li>examples:<ul>
<li><a href="http://34.69.204.31:5000/add?x=10&amp;y=20" target="_blank" rel="noopener">http://34.69.204.31:5000/add?x=10&amp;y=20</a></li>
<li><a href="http://34.69.204.31:5000/survey?major=CS" target="_blank" rel="noopener">http://34.69.204.31:5000/survey?major=CS</a></li>
<li><a href="http://34.69.204.31:5000/survey?major=Mechanical" target="_blank" rel="noopener">http://34.69.204.31:5000/survey?major=Mechanical</a> Engineering</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><code>flask.request.args</code> enables us process query string<br><a href="mailto:`@app.route" target="_blank" rel="noopener">`@app.route</a>(“<url>“, methods=[“POST”])<code>enables us to process HTTP POST requests</code>flask.request.get_data()` enables us to access data (byte format) sent via HTTP POST request</url></p>
<h2 id="Binding-a-Function-to-an-URL-Path"><a href="#Binding-a-Function-to-an-URL-Path" class="headerlink" title="Binding a Function to an URL Path"></a>Binding a Function to an URL Path</h2><pre class="line-numbers language-python"><code class="language-python">@app<span class="token punctuation">.</span>route<span class="token punctuation">(</span><span class="token string">"/index"</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">index</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token string">"Hello World!"</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>binds the <code>index</code> function to the page <code>IP address/index</code>, meaning it will display a web page that says “Hello World”.</p>
<p>“Hello World” can be replaced by any text or HTML string, which can be read from an HTML file and modified in the <code>index()</code> function.</p>
<p>HTML string can be read from existing HTML files then modified, for example</p>
<p><code>with open(&quot;index.html&quot;) as f:</code> <code>return f.read()</code>.</p>
<p>It can also be generated by packages such as pandas, for example, <code>pandas.read_csv(&quot;data.csv&quot;).to_html()</code>.</p>
<h2 id="Binding-Multiple-Paths"><a href="#Binding-Multiple-Paths" class="headerlink" title="Binding Multiple Paths"></a>Binding Multiple Paths</h2><pre class="line-numbers language-python"><code class="language-python">@app<span class="token punctuation">.</span>route<span class="token punctuation">(</span><span class="token string">"/index/&lt;x>"</span><span class="token punctuation">)</span> 
    <span class="token keyword">def</span> <span class="token function">index</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span> 
        <span class="token keyword">return</span> f<span class="token string">"Hello {x}"</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>To bind multiple paths, variable rules can be added,  will display a web page that says “Hello World” when the path <code>IP address/index/World</code> is used.</p>
<p>The variable <code>x</code> can also be converted to another type for the <code>index(x)</code> function.</p>
<table>
<thead>
<tr>
<th>Route</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="mailto:`@app.route" target="_blank" rel="noopener">`@app.route</a>(“/index/<x>“)`</x></td>
<td>string</td>
<td>Default</td>
</tr>
<tr>
<td><a href="mailto:`@app.route" target="_blank" rel="noopener">`@app.route</a>(“/index/<a href="int:x" target="_blank" rel="noopener">int:x</a>“)`</td>
<td>int</td>
<td>Convert to Integer</td>
</tr>
<tr>
<td><a href="mailto:`@app.route" target="_blank" rel="noopener">`@app.route</a>(“/index/<a href="float:x" target="_blank" rel="noopener">float:x</a>“)`</td>
<td>float</td>
<td>Convert to Float</td>
</tr>
<tr>
<td><a href="mailto:`@app.route" target="_blank" rel="noopener">`@app.route</a>(“/index/<a href="path:x" target="_blank" rel="noopener">path:x</a>“)`</td>
<td>path</td>
<td>String but allows <code>/</code></td>
</tr>
</tbody>
</table>
<h2 id="Redirect"><a href="#Redirect" class="headerlink" title="Redirect"></a>Redirect</h2><p><code>return flask.redirect(url)</code> redirects the current path to another with URL <code>url</code>.</p>
<p><code>return flask.redirect(flask.url_for(&quot;index&quot;))</code> redirects the current path to another which <strong>binds to the function</strong> <code>index()</code>.</p>
<p><code>return flask.redirect(flask.url_for(&quot;index&quot;, x = &quot;World&quot;))</code> redirects the current path to another which <strong>binds to the function</strong> <code>index(&quot;World&quot;)</code>.</p>
<h2 id="Collecting-Information"><a href="#Collecting-Information" class="headerlink" title="Collecting Information"></a>Collecting Information</h2><p><code>flask.request.remote_addr</code> can be used to <strong>find the remote IP address of the visitor</strong></p>
<p>IP addresses can be then used to find visitor information such as their service provider, location (country, state, city)</p>
<p><code>flask.request.user_agent.string</code> can be used to <strong>find the user agent of the visitor</strong>.</p>
<p>User Agent information can be used to find browser, operating system, device information</p>
<p>The visitors’ IP addresses then can be stored in global variable or saved to a file on the server to <strong>keep track of who visited each page and when</strong>. </p>
<h2 id="Rate-Limiting"><a href="#Rate-Limiting" class="headerlink" title="Rate Limiting"></a>Rate Limiting</h2><p>One use of such visitor information is for rate limiting: preventing visitors from loading the pages too often, for example, to prevent web scraping.</p>
<p>In this case, the visitor’s IP address and visit time can be stored in a list: in case the next visit time is too close to the previous one, the visitor can be redirected to another page, or more commonly, responded with a error message, for example, <code>return flask.Response(&quot;...&quot;, status = 429, headers = {&quot;Retry-After&quot;: &quot;60&quot;}</code> tells the visitor to retry after 60 seconds.</p>
<p>A list of response status and header fields can be found: here <code>status = 429</code> says “Too Many Requests”.</p>
<p><code>requests</code> module:</p>
<ul>
<li><code>resp = requests.get(&lt;URL&gt;)</code> method: enables us to send HTTP GET request</li>
<li><code>resp.status_code</code>: status code of the response</li>
<li><code>resp.text</code>: <code>str</code> text content of the response</li>
<li><code>resp.headers</code>: <code>dict</code> content of response headers</li>
</ul>
<h2 id="Live-Plots-on-Flask-Sites"><a href="#Live-Plots-on-Flask-Sites" class="headerlink" title="Live Plots on Flask Sites"></a>Live Plots on Flask Sites</h2><p>A function that returns an image response can be used for <a href="mailto:`@app.route" target="_blank" rel="noopener">`@app.route</a>(“/plot.png”)<code>or</code>@app.route(“/plot.svg”)`. (SVG is <strong>Scalable Vector Graphics</strong> and vector graphics is represented by a list of geometric shapes such as points, lines, curves, PNG is <strong>Portable Network Graphics</strong> and <strong>raster graphics</strong> is represented by a matrix of pixel color values)</p>
<p>An image response can be created using <code>flask.Response(image, headers={&quot;Content-Type&quot;: &quot;image/png&quot;})</code> or <code>flask.Response(image, headers={&quot;Content-Type&quot;: &quot;image/svg+xml&quot;})</code>, where the image is a <code>bytes</code> object and can be obtained using <code>io.BytesIO.getvalue()</code> where <code>io.BytesIO</code> creates a “fake” file to store the image.</p>
<p>On the web page, display the image as <code>&lt;img src=&quot;plot.png&quot;&gt;</code> or <code>&lt;img src=&quot;plot.svg&quot;&gt;</code>.</p>
<h1 id="AB-Testing"><a href="#AB-Testing" class="headerlink" title="AB Testing"></a>AB Testing</h1><h2 id="Concept"><a href="#Concept" class="headerlink" title="Concept"></a>Concept</h2><p>Two or more versions of the same page can be displayed to the visitor randomly to compare which one is better.</p>
<p>The comparison is often based on <strong>click-through rates (CTR)</strong>, which is computed as the number of clicks on a specific link on the page divided by the number of times the page is displayed to the visitor.</p>
<p>CTR is also used for advertisement, computed as the number of clicks on the ad divided by the number of times the ad is shown to the visitor.</p>
<h2 id="Click-Through-Rate-Example"><a href="#Click-Through-Rate-Example" class="headerlink" title="Click Through Rate Example"></a>Click Through Rate Example</h2><p>Suppose the number of clicks are summarized in the following table, what are the click through rates, and is A statistically significantly better than B?</p>
<table>
<thead>
<tr>
<th>Version</th>
<th>click</th>
<th>no click</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>30</td>
<td>60</td>
</tr>
<tr>
<td>B</td>
<td>25</td>
<td>75</td>
</tr>
</tbody>
</table>
<p>The CTR for A is $$\frac{30}{30+60}=\frac{1}{3}$$</p>
<p>The CTR for B is $$\frac{25}{25+75}=\frac{1}{4}$$</p>
<p><strong>Determine whether A is better than B:</strong></p>
<ul>
<li><code>scipy.stats.fisher_exact([[30, 60], [25, 75]]).pvalue=0.1075</code></li>
</ul>
<p>原假设 A 不如 B</p>
<p>If a 5 percent threshold is used: 0.1075 &gt; 0.05, 否定原假设，A 并不是显著大于B</p>
<p> if a 20 percent threshold is used: 0.1075 &lt; 0.2, 接受原假设 ，A显著好于B</p>
<p>总结： <code>scipy.stats.fisher_exact([[30, 60], [25, 75]]).pvalue</code>，大于threshold，前面不如后面，小于则一定前面好于后面</p>
<h3 id="Two-situations-when-pvalue-will-be-lower-than-significance-threshold"><a href="#Two-situations-when-pvalue-will-be-lower-than-significance-threshold" class="headerlink" title="Two situations when pvalue will be lower than significance threshold"></a>Two situations when pvalue will be lower than significance threshold</h3><ol>
<li>Sample size is the same, but skew is very heavy — unlikely to have that by chance ，差距大？</li>
</ol>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Scenario 1: </span>
<span class="token comment" spellcheck="true"># Sample size is the same, but skew is very heavy --- </span>
<span class="token comment" spellcheck="true"># unlikely to have that by chance</span>

df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">"click"</span><span class="token punctuation">:</span>    <span class="token punctuation">{</span><span class="token string">"A"</span><span class="token punctuation">:</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token string">"B"</span><span class="token punctuation">:</span> <span class="token number">75</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">"no-click"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">"A"</span><span class="token punctuation">:</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token string">"B"</span><span class="token punctuation">:</span> <span class="token number">25</span><span class="token punctuation">}</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
_<span class="token punctuation">,</span> pvalue <span class="token operator">=</span> stats<span class="token punctuation">.</span>fisher_exact<span class="token punctuation">(</span>df<span class="token punctuation">)</span>
pvalue <span class="token comment" spellcheck="true">#0.00042033045869994034</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol start="2">
<li>Sample size is large, but skew is small</li>
</ol>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Scenario 2: </span>
<span class="token comment" spellcheck="true"># Sample size is large, but skew is small </span>

df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">"click"</span><span class="token punctuation">:</span>    <span class="token punctuation">{</span><span class="token string">"A"</span><span class="token punctuation">:</span> <span class="token number">500</span><span class="token punctuation">,</span> <span class="token string">"B"</span><span class="token punctuation">:</span> <span class="token number">550</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">"no-click"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">"A"</span><span class="token punctuation">:</span> <span class="token number">500</span><span class="token punctuation">,</span> <span class="token string">"B"</span><span class="token punctuation">:</span> <span class="token number">450</span><span class="token punctuation">}</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
_<span class="token punctuation">,</span> pvalue <span class="token operator">=</span> stats<span class="token punctuation">.</span>fisher_exact<span class="token punctuation">(</span>df<span class="token punctuation">)</span>
pvalue <span class="token comment" spellcheck="true"># 0.02820356890423392</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Displaying-Pages"><a href="#Displaying-Pages" class="headerlink" title="Displaying Pages"></a>Displaying Pages</h2><p>The choice of which page to display can <strong>be random</strong>, for example, <code>if random.random() &lt; 0.5:</code> <code>return &quot;Version A&quot;</code> <code>else</code> <code>return &quot;Version B&quot;</code>.</p>
<p>It can also be displayed in a <strong>fixed ordering</strong>, for example, suppose <code>count</code> is a global variable to keep track of the number of visitors, then <code>if count % 2 == 0:</code> <code>return &quot;Version A&quot;</code> <code>else</code> <code>return &quot;Version B&quot;</code> <code>count = count + 1</code> would alternate between the two versions.</p>
<p>This can be done for a fixed number of times, and after that, <strong>only the one with higher click-through rate</strong> would be displayed to all visitors.</p>
<h2 id="Query-Strings"><a href="#Query-Strings" class="headerlink" title="Query Strings"></a>Query Strings</h2><p><code>&quot;index?x=1&amp;y=2&quot;</code> is a URL specifying the path <code>&quot;index&quot;</code> with the query string <code>x=1</code> and <code>y=2</code>.</p>
<p>Use <code>flask.request.args</code> to get a dictionary of <strong>key-value pairs of the query string</strong>.</p>
<p>To perform AB testing of a page with two versions, both contain a link to <code>index</code>: on version A, the URL can be <code>&lt;a href=&quot;index?from=A&quot;&gt;Link&lt;\a&gt;</code>, and on version B, the same URL can be <code>&lt;a href=&quot;index?from=B&quot;&gt;Link&lt;\a&gt;</code>.</p>
<p>If version A URL is used, <code>request.args[&quot;from&quot;]</code> would be <code>&quot;A&quot;</code> and if version B URL is used <code>request.args[&quot;from&quot;]</code> would be <code>&quot;B&quot;</code>.</p>
<h2 id="Multi-Armed-Bandit"><a href="#Multi-Armed-Bandit" class="headerlink" title="Multi-Armed Bandit"></a>Multi-Armed Bandit</h2><p>The previous design has experiments with alternatives for <strong>a fixed number</strong> of time then exploit the best alternatives.</p>
<p>This design can lead to a large “regret”, for example, if displaying bad version is costly. In other settings such as drug or vaccine trials and stock selection, experimenting with bad alternatives can be costly.</p>
<p>The problem of optimal experimentation vs exploitation is studied in reinforcement learning as the multi-armed bandit problem:</p>
<h1 id="Upper-Confidence-Bound"><a href="#Upper-Confidence-Bound" class="headerlink" title="Upper Confidence Bound"></a>Upper Confidence Bound</h1><p><strong>Upper Confidence Bound (UCB)</strong> is a <strong>no-regret</strong> algorithm that minimizes the loss from experimentation.</p>
<p>After every version is displayed once, the algorithm <strong>keeps track of the average value</strong> (for example click-through rate) from each version, say $ \hat{\mu_A},\hat{\mu_B} $, computes the UCBs $\hat{\mu_A} + c \sqrt{ \frac{2 log(n)}{n_A}}$ and $\hat{\mu_B} + c \sqrt{ \frac{2 log(n)}{n_B}}$</p>
<p>where $n$ is the total number of visitors, $n_A$ is the number of visitors of version A, $n_B$ is the number of visitors of version B, and $c$ is a constant, and always picks the version with a higher UCB.</p>
<p>The UCB algorithm uses the principle of optimism under uncertainty and the UCBs are <strong>optimistic guesses</strong>: with high probability (the probability can be determined by $c$), the actual average is less than UCB.</p>
<p>UCB, choose the <strong>highest UCB</strong> verison</p>
<h1 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h1><h2 id="Visual-Encodings"><a href="#Visual-Encodings" class="headerlink" title="Visual Encodings"></a>Visual Encodings</h2><p><strong>Position, size, shape (style), value (light to dark), color (hue), orientation, and texture</strong> can be used to present data points in different dimensions. These are called visual encodings.</p>
<p>Some of these encodings are better for different types of features (data dimensions).</p>
<table>
<thead>
<tr>
<th>Encoding</th>
<th>Continuous</th>
<th>Ordinal</th>
<th>Discrete (Categorical)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Position</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Size</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr>
<td>Shape</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Value</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr>
<td>Color</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Orientation</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Texture</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
</tr>
</tbody>
</table>
<h2 id="Seaborn-Plots"><a href="#Seaborn-Plots" class="headerlink" title="Seaborn Plots"></a>Seaborn Plots</h2><p><code>seaborn</code> is one of the data visualization libraries that can make plots for exploring the datasets with a few dimensions</p>
<p>Suppose the columns are indexed by <code>c1</code>, <code>c2</code>, …, then <code>seaborn.relplot(data = ..., x = &quot;c1&quot;, y = &quot;c2&quot;, hue = &quot;c3&quot;, size = &quot;c4&quot;, style = &quot;c5&quot;)</code> visualizes the relationship between the columns by encoding <code>c1</code> by x-position, <code>c2</code> by y-position, <code>c3</code> by color hue if the feature is discrete, and by color value if it is continuous, <code>c4</code> by size, <code>c5</code> by shape (for example, o’s and x’s for points, solid and dotted for lines) if the feature is discrete.</p>
<h3 id="Multiple-Plots"><a href="#Multiple-Plots" class="headerlink" title="Multiple Plots"></a>Multiple Plots</h3><p>For discrete dimensions with a small numbers of categories, multiple plots can be made, one for each category.</p>
<p><code>seaborn.relplot(data = ..., ..., col = &quot;c6&quot;, row = &quot;c7&quot;)</code> produces <strong>multiple columns of plots</strong> one for each category of <code>c6</code>, and <strong>multiple rows of plots</strong> one for each category of <code>c7</code>.</p>
<p><code>seaborn.pairplot</code> produces a scatter plot for each pair of columns (features) which could be useful for exploring relationships between pairs of continuous features too.</p>
<h2 id="Chernoff-Face-Example"><a href="#Chernoff-Face-Example" class="headerlink" title="Chernoff Face Example"></a>Chernoff Face Example</h2><p>Chernoff faces can be used to display small low dimensional datasets. The shape, size, placement and orientation of eyes, ears, mouth and nose are visual encodings</p>
<p><code>ChernoffFace</code> is a package to draw Chernoff Faces</p>
<p>Facial features can be manually designed and plotted in <code>matplotlib</code>.</p>
<p><img src="/2023/10/07/CS320学习笔记/18.png" alt></p>
<h2 id="Plotting-High-Dimensional-Data-Sets"><a href="#Plotting-High-Dimensional-Data-Sets" class="headerlink" title="Plotting High Dimensional Data Sets"></a>Plotting High Dimensional Data Sets</h2><p>If there are large numbers of dimensions and data points, plotting them directly is inappropriate.</p>
<p>To figure out the most important dimensions, which are not necessarily one of the original dimensions, unsupervised machine learning techniques can be used.</p>
<p>One example of such dimensionality reduction algorithms is called Principal Component Analysis (PCA)</p>
<h2 id="Graph"><a href="#Graph" class="headerlink" title="Graph"></a>Graph</h2><p>A graph can be represented by <strong>node-link lists</strong> or <strong>adjacency matrices</strong>.</p>
<p>To find patterns (for example clusters) in a graph, the positions of the nodes in node-link diagrams or ordering of nodes in adjacency matrices may need to be changed.</p>
<h3 id="Layout"><a href="#Layout" class="headerlink" title="Layout"></a>Layout</h3><p>Circular layout and arc (chord) layout are simple for the computer, but difficult for humans to understand the shape of the graph</p>
<p>Force-Directed Placement (FDP) treats nodes as points and edges as springs and tries to minimize energy. It is also called spring model layout</p>
<h3 id="Tree-Diagrams"><a href="#Tree-Diagrams" class="headerlink" title="Tree Diagrams"></a>Tree Diagrams</h3><p>Trees are special graphs for which <strong>each node has one parent,</strong> and there are more ways to visualize a tree</p>
<p>Many of these visualizations are not available in standard Python plotting packages, but the nodes and edges can plotted “manually” using <code>matplotlib</code>.</p>
<h3 id="Primitives"><a href="#Primitives" class="headerlink" title="Primitives"></a>Primitives</h3><p>Custom visualization steps:</p>
<ul>
<li>draw “patches” (shapes) on the screen (what):<ul>
<li>lines</li>
<li>polygons</li>
<li>circle</li>
<li>text</li>
</ul>
</li>
<li>location of the “patches” on the screen (where):<ul>
<li>X &amp; Y co-ordinate</li>
<li>“Coordinate Reference System (CRS)”:<ul>
<li>takes some X &amp; Y and maps it on to actual space on screen</li>
<li>several CRS</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Review-drawing-a-figure"><a href="#Review-drawing-a-figure" class="headerlink" title="Review: drawing a figure"></a>Review: drawing a figure</h3><ul>
<li><code>fig, ax = plt.subplots(figsize=(&lt;width&gt;, &lt;height&gt;))</code></li>
</ul>
<h3 id="Drawing-a-circle"><a href="#Drawing-a-circle" class="headerlink" title="Drawing a circle"></a>Drawing a circle</h3><ul>
<li>Type <code>plt.</code> and then tab to see a list of <code>patches</code>.</li>
<li><code>plt.Circle((&lt;X&gt;, &lt;Y&gt;), &lt;RADIUS&gt;)</code></li>
<li>To see the cicle, we need to invoke either:<ul>
<li><code>ax.add_patch(&lt;circle object&gt;)</code></li>
<li><code>ax.add_artist(&lt;circle object&gt;)</code></li>
<li>this invocation needs to be in the same cell as the one that draws the figure</li>
<li>Is there a difference between <code>ax.add_patch</code>and <code>ax.add_artist</code>?<ul>
<li><code>ax.autoscale_view()</code>: automatically chose limits for the axes; typically works better with <code>ax.add_patch(...)</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python">fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># Let's draw a circle at (0.5, 0.5) of radius 0.3</span>
c <span class="token operator">=</span> plt<span class="token punctuation">.</span>Circle<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># type: matplotlib.patches.Circle</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Aspect-Ratio"><a href="#Aspect-Ratio" class="headerlink" title="Aspect Ratio"></a>Aspect Ratio</h3><ul>
<li><code>ax.set_aspect(&lt;Y DIM&gt;)</code>: how much space y axes takes with respect to x axes space</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python">fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> plt<span class="token punctuation">.</span>Circle<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>add_artist<span class="token punctuation">(</span>c<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># Set aspect for y-axis to 1</span>
ax<span class="token punctuation">.</span>set_aspect<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/2023/10/07/CS320学习笔记/24.png" alt></p>
<pre class="line-numbers language-python"><code class="language-python">fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># Set x axis limit to (0, 3)</span>
ax<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> plt<span class="token punctuation">.</span>Circle<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>add_artist<span class="token punctuation">(</span>c<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># Set aspect for y-axis to 3</span>
ax<span class="token punctuation">.</span>set_aspect<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/2023/10/07/CS320学习笔记/25.png" alt></p>
<p><code>matplotlib.patches</code> contain primitive geometries such as <code>Circle</code>, <code>Ellipse</code>, <code>Polygon</code>, <code>Rectangle</code>, <code>RegularPolygon</code> and <code>ConnectionPatch</code>, <code>PathPatch</code>, <code>FancyArrowPatch</code></p>
<p><code>matplotlib.text</code> can be used to draw text; it can render math equations using TeX too</p>
<p>A node (indexed <code>i</code>) at ($x,y$) can be represented by a closed shape such as a circle with radius <code>r</code>, for example, <code>matplotlib.patches.Circle((x, y), r)</code>, and <code>matplotlib.text(x, y, &quot;i&quot;)</code>.<br>➭ An edge from a node at ($x_1,y_1$) to a node at ($x_2,y_2$) can be represented by a path (line or curve, with or without arrow), </p>
<p><strong>Lines:</strong> for example, <code>matplotlib.patches.FancyArrowPatch((x1, y1), (x2, y2))</code>, or if the nodes are on different subplots with axes <code>ax[0]</code>, <code>ax[1]</code>, <code>matplotlib.patches.ConnectionPath((x1, y1), (x2, y2), &quot;data&quot;, axesA = ax[0], axesB = ax[1])</code> 两点连线<br>➭ To specify the layout of a graph, a list of positions of the nodes are required (sometimes parameters for the curve of the edges need to be specified too).</p>
<h3 id="Curves"><a href="#Curves" class="headerlink" title="Curves"></a>Curves</h3><p>A curve (with arrow) from ($x_1,y_1$) to ($x_2,y_2$) can be specified by the (1) out-angle and in-angle, (2) curvature of the curve, (3) Bezier control points</p>
<p><code>FancyArrowPatch((x1, y1), (x2, y2), connectionstyle=ConnectionStyle.Angle3(angleA = a, angleB = b)</code> plots a quadratic Bezier curve starting from ($x_1,y_1$) going out at an angle <code>a</code> and going in at an angle <code>b</code> to ($x_2,y_2$). 中间控制点$(x_0,y_0)$,angle $\theta_A= arctan(\frac{y_0-y_1}{x_0-x_1})$ $\theta_B= arctan(\frac{y_0-y_2}{x_0-x_2})$<br>➭ <code>FancyArrowPatch((x1, y1), (x2, y2), connectionstyle=ConnectionStyle.Arc3(rad = r)</code> plots a quadratic Bezier curve from ($x_1,y_1$) to ($x_2,y_2$) that arcs towards a point <strong>at distance <code>r</code> times the length of the line from the line</strong> connecting ($x_1,y_1$) and ($x_2,y_2$). 中心控制点在两点的垂直平分线上谜案，r代表控制点到中点的距离是两个点距离的几倍</p>
<p><strong>examples:</strong></p>
<p>How to draw a quadratic Bezier curve with control points <code>(0, 0), (1, 0), (1, 1)</code>?<br>➭ This curve has the same shape as the curve drawn in the “Curve Example”: in particular, the start angle is 0 degrees (measured from the positive x-axis direction) and the end angle is 270 degrees or -90 degrees, and the distance of the line segment connecting the midpoint between <code>(0, 0)</code> and <code>(1, 1)</code> (which is <code>(1/2, 1/2)</code>) and the middle control point (which is <code>(1, 0)</code>) is half of the length of the line segment connecting <code>(0, 0)</code> and <code>(1, 1)</code>, or $\sqrt{(1-\frac{1}{2})^2+(0-\frac{1}{2})^2}=\frac{1}{2}\sqrt{(1-0)^2+(1-0)^2}$.<br>➭ Therefore, use any path patch with connectionstyle <code>ConnectionStyle.Angle3(0, -90)</code> or <code>ConnectionStyle.Arc3(1/2)</code> to plot the curve.</p>
<p><img src="/2023/10/07/CS320学习笔记/19.png" alt></p>
<p> The curves can be constructed by recursively interpolating the line segments between the control points</p>
<p><code>PathPatch(Path([(x1, y1), (x2, y2), (x3, y3)], [Path.MOVETO, Path.CURVE3, Path.CURVE3]))</code> draws a Bezier curve from  ($x_1,y_1$) to ($x_3,y_3$) with a control point ($x_2,y_2$).</p>
<p><code>PathPatch(Path([(x1, y1), (x2, y2), (x3, y3), (x4, y4)], [Path.MOVETO, Path.CURVE4, Path.CURVE4, Path.CURVE4]))</code> draws a Bezier curve from  ($x_1,y_1$) to ($x_4,y_4$) with two control points  ($x_2,y_2$) and ($x_3,y_3$).</p>
<h2 id="Coordinate-Systems"><a href="#Coordinate-Systems" class="headerlink" title="Coordinate Systems"></a>Coordinate Systems</h2><ul>
<li><p><code>fig, ax = plt.subplots(figsize=(&lt;width&gt;, &lt;height&gt;), ncols=&lt;N&gt;, nrows=&lt;N&gt;)</code></p>
<ul>
<li>ncols: split into vertical sub plots</li>
<li>nrows: split into horizontal sub plots</li>
</ul>
</li>
<li><p><code>ax.set_xlim(&lt;lower limit&gt;, &lt;upper limit&gt;)</code>: set x-axis limits</p>
</li>
<li><p><code>ax.set_ylim(&lt;lower limit&gt;, &lt;upper limit&gt;)</code>: set y-axis limits</p>
</li>
</ul>
<p>The primitive geometries can be specified using any of them by specifying the <code>transform</code> argument, for example for a figure <code>fig</code> and axis <code>ax</code>, <code>Circle((x, y), r, transform = ax.transData)</code>, <code>Circle((x, y), r, transform = ax.transAxes)</code>, <code>Circle((x, y), r, transform = fig.transFigure)</code>, or <code>Circle((x, y), r, transform = fig.dpi_scale_trans)</code>.</p>
<h3 id="ax-transData"><a href="#ax-transData" class="headerlink" title="ax.transData"></a><code>ax.transData</code></h3><ul>
<li><code>color</code> parameter controls the color of the “patch”</li>
<li><code>edgecolor</code> parameter controls outer border color of the “patch”</li>
<li><code>linewidth</code> parameter controls the size of the border of the “patch”</li>
<li><code>facecolor</code> parameter controls the filled in color of the “patch”</li>
</ul>
<table>
<thead>
<tr>
<th>Coordinate System</th>
<th>Bottom left</th>
<th>Top right</th>
<th>Transform</th>
</tr>
</thead>
<tbody>
<tr>
<td>Data</td>
<td>based on data</td>
<td>based on data</td>
<td><code>ax.transData</code> (default)</td>
</tr>
<tr>
<td>Axes</td>
<td>(0,0)</td>
<td>(1,1)</td>
<td><code>ax.transAxes</code></td>
</tr>
<tr>
<td>Figure</td>
<td>(0,0)</td>
<td>(1,1)</td>
<td><code>fig.transFigure</code></td>
</tr>
<tr>
<td>Display</td>
<td>(0,0)</td>
<td>($w,h$) in inches</td>
<td><code>fig.dpi_scale_trans</code></td>
</tr>
</tbody>
</table>
<p>(1) <code>ax.transData</code></p>
<p><img src="/2023/10/07/CS320学习笔记/20.png" alt></p>
<p>(2) <code>ax.transAxes</code></p>
<p><img src="/2023/10/07/CS320学习笔记/21.png" alt></p>
<p>(3) <code>fig.transFigure</code></p>
<p><img src="/2023/10/07/CS320学习笔记/22.png" alt></p>
<p>(4) <code>fig.dpi_scale_trans</code></p>
<p><img src="/2023/10/07/CS320学习笔记/23.png" alt></p>
<pre class="line-numbers language-python"><code class="language-python">fig<span class="token punctuation">,</span> <span class="token punctuation">(</span>ax1<span class="token punctuation">,</span> ax2<span class="token punctuation">)</span> <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>ncols<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
ax2<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Left subplot</span>
c <span class="token operator">=</span> plt<span class="token punctuation">.</span>Circle<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>ax1<span class="token punctuation">.</span>transAxes<span class="token punctuation">)</span>
ax1<span class="token punctuation">.</span>add_artist<span class="token punctuation">(</span>c<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Right subplot</span>
c <span class="token operator">=</span> plt<span class="token punctuation">.</span>Circle<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>ax2<span class="token punctuation">.</span>transAxes<span class="token punctuation">)</span>
ax2<span class="token punctuation">.</span>add_artist<span class="token punctuation">(</span>c<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># whole figure</span>
<span class="token comment" spellcheck="true"># edgecolor="red", facecolor="none", linewidth=3</span>
c <span class="token operator">=</span> plt<span class="token punctuation">.</span>Circle<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>fig<span class="token punctuation">.</span>transFigure<span class="token punctuation">,</span> edgecolor<span class="token operator">=</span><span class="token string">"red"</span><span class="token punctuation">,</span> facecolor<span class="token operator">=</span><span class="token string">"none"</span><span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
fig<span class="token punctuation">.</span>add_artist<span class="token punctuation">(</span>c<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/2023/10/07/CS320学习笔记/26.png" alt></p>
<h3 id="No-CRS-raw-pixel-coordinates"><a href="#No-CRS-raw-pixel-coordinates" class="headerlink" title="No CRS (raw pixel coordinates)"></a>No CRS (raw pixel coordinates)</h3><ul>
<li><code>fig.dpi</code>: dots (aka pixesl) per inch</li>
<li>increasing dpi makes the figure have higher resolution (helpful when you want to print a large size)</li>
<li>Review:<ul>
<li><code>plt.tight_layout()</code>: avoid unncessary cropping of the figure — always needed for No CRS cases</li>
<li><code>fig.savefig(&lt;relative path.png&gt;)</code>: to save a local copy of the image</li>
</ul>
</li>
</ul>
<h2 id="Map-Projections"><a href="#Map-Projections" class="headerlink" title="Map Projections"></a>Map Projections</h2><p>Positions on a map are usually specified by a longitude and a latitude. It is often used in <strong>Geographic Coordinate Systems (GCS)</strong>.</p>
<p>They are angles in degrees specifying a position on a sphere.</p>
<p>It is difficult to compute areas and distances with angles, so when plotting positions on maps, it is easier to use meters, or Coordinate Reference Systems (CRS).</p>
<p>A region on a map can be represented by <strong>one or many polygons</strong>.</p>
<p>A polygon is specified by a list of <strong>points connected by line segments</strong>.</p>
<p>Information about the polygons are stored in <code>shp</code>, <code>shx</code> and <code>dbf</code> files.</p>
<h2 id="GeoPandas"><a href="#GeoPandas" class="headerlink" title="GeoPandas"></a>GeoPandas</h2><p><code>GeoPandas</code> package can read shape files into DataFrames and <code>matplotlib</code> can be used to plot them.</p>
<p><code>geopandas.read_file(...)</code> can be used to read a zip file containing <code>shp</code>, <code>shx</code> and <code>dbf</code> files, and output a <code>GeoDataFrame</code>, which a <code>pandas</code> DataFrame with a column <strong>specifying the geometry of the item</strong>.</p>
<p><code>GeoDataFrame.plot()</code> can be used to <strong>plot the polygons</strong>.</p>
<h3 id="Conversion-from-GCS-to-CRS"><a href="#Conversion-from-GCS-to-CRS" class="headerlink" title="Conversion from GCS to CRS"></a>Conversion from GCS to CRS</h3><p><code>GeoDataFrame.crs</code> <strong>checks the coordinate system</strong> used in the data frame.</p>
<p><code>GeoDataFrame.to_crs(&quot;epsg:326??&quot;)</code> or <code>GeoDataFrame.to_crs(&quot;epsg:326??)</code> can be used to convert from degree-based coordinate system to meter-based coordinate system.</p>
<p>The <code>??</code> in the European Petroleum Survey Group (EPSG) code specifies the Universal Transverse Mercator (UTM) zone<br>➭ Madison, Wisconsin is in Zone 16.</p>
<h3 id="Polygons"><a href="#Polygons" class="headerlink" title="Polygons"></a>Polygons</h3><h4 id="Shapely-shapes"><a href="#Shapely-shapes" class="headerlink" title="Shapely shapes"></a>Shapely shapes</h4><p><strong>Point, LineString, Polygon, MultiPolygon</strong></p>
<ul>
<li><p><code>from shapely.geometry import Point, Polygon, box</code></p>
</li>
<li><p><code>Polygon([(&lt;x1&gt;, &lt;y1&gt;), (&lt;x2&gt;, &lt;y2&gt;), (&lt;x3&gt;, &lt;y3&gt;), ...])</code> polygon.Polygon</p>
</li>
<li><p><code>box(&lt;x1&gt;, &lt;x2&gt;, &lt;y1&gt;, &lt;y2&gt;)</code> polygon.Polygon</p>
</li>
<li><p><code>Point(&lt;x&gt;, &lt;y&gt;)</code> point.Point</p>
</li>
<li><p><code>&lt;shapely object&gt;.buffer(&lt;size&gt;)</code></p>
<ul>
<li>example: <code>Point(5, 5).buffer(3)</code> creates a circle</li>
</ul>
</li>
<li><p>Shapely methods:</p>
<ul>
<li><code>union</code>: any point that is in either shape (OR)</li>
<li><code>intersection</code>: any point that is in both shapes (AND)</li>
<li><code>difference</code>: subtraction</li>
<li><code>intersects</code>: do they overlap?</li>
</ul>
</li>
</ul>
<h4 id="Creating"><a href="#Creating" class="headerlink" title="Creating"></a>Creating</h4><p>Polygons can be created manually from the vertices using <code>shapely</code> too</p>
<p><code>Point(x, y)</code> creates <strong>a point</strong> at ($x,y$).</p>
<p><code>LineString([x1, y1], [x2, y2])</code> or <code>LineString(Point(x1, y1), Point(x2, y2))</code> <strong>creates a line</strong> from ($x_1,y_1$) to ($x_2,y_2$).</p>
<p><code>Polygon([[x1, y1], [x2, y2], ...])</code> or <code>Polygon([Point(x1, y1), Point(x2, y2), ...])</code> <strong>creates a polygon connecting the vertices</strong>  ($x_1,y_1$), ($x_2,y_2$)., …</p>
<p><code>box(xmin, ymin, xmax, ymax)</code> is another way to <strong>create a rectangular</strong> <code>Polygon</code></p>
<h4 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h4><p><code>Polygon.area</code> or <code>MultiPolygon.area</code> computes <strong>the area of the polygon</strong> 面积</p>
<p><code>Polygon.centroid</code> computes the <strong>centroid (center) of the polygon</strong> 中心</p>
<p><code>Polygon.buffer(r)</code> computes the geometry containing all points within a <code>r</code> distance from the polygon. 并不是从中心画圆</p>
<p>If <code>Point.buffer(r)</code> is used, <strong>the resulting geometry is a circle with radius <code>r</code></strong> around the point, and <code>Point.buffer(r, cap_style = 3)</code> is a square with “radius” <code>r</code> around the point</p>
<p>以中心画一个半径为r的圆</p>
<h4 id="Manipulation"><a href="#Manipulation" class="headerlink" title="Manipulation"></a>Manipulation</h4><p>Union and intersections of polygons <strong>are still polygons</strong>.</p>
<p><code>geopandas.overlay(x, y, how = &quot;intersection&quot;)</code> computes the polygons that is <strong>the intersection of</strong> polygons <code>x</code> and <code>y</code>, 返回交集</p>
<p><code>.intersects()</code>返回是否相交</p>
<p> if <code>GeoDataFrame</code> has geometry <code>x</code>, <code>GeoDataFrame.intersection(y)</code> computes <strong>the same intersection</strong></p>
<p><code>GeoDataFrame.difference(y)</code>: Returns a <code>GeoSeries</code> of the points in each aligned geometry that are not in other.</p>
<p><code>.symmetric_difference()</code>: Returns a <code>GeoSeries</code> of the symmetric difference of points in each aligned geometry with other.</p>
<p><code>geopandas.overlay(x, y, how = &quot;union&quot;)</code> computes the polygons that <strong>is the union of polygons <code>x</code> and <code>y</code></strong>， if <code>GeoDataFrame</code> has geometry <code>x</code>, <code>GeoDataFrame.union(y)</code> <strong>computes the same union</strong></p>
<p><code>GeoDataFrame.unary_union</code> is the single <strong>combined <code>MultiPolygon</code> of all polygons</strong> in the data frame</p>
<p><code>GeoDataFrame.convex_hull</code> computes <strong>the convex hull</strong> (smallest convex polygon that contains the original polygon)</p>
<h4 id="Convex"><a href="#Convex" class="headerlink" title="Convex"></a>Convex</h4><p>A shape is <strong>convex</strong> if the shape contains the whole line segment between any two points in the shape. </p>
<p><code>box(0, 0, 1, 1)</code>: yes, all rectangles are convex.</p>
<p><code>Point(0, 0).buffer(1)</code>: yes, all circles (or polygon approximations of circles) are convex.</p>
<p><code>Polygon([[0, 0], [1, 0], [0, 1]]</code>: yes, any triangle is convex.</p>
<p><code>box(0, 0, 2, 2).intersect(box(1, 1, 3, 3))</code>: yes, the intersection here is just <code>box(1, 1, 2, 2)</code>, and in general, the intersection between any two convex shapes is still convex.</p>
<p><code>box(0, 0, 2, 2).union(box(1, 1, 3, 3))</code>: no, the line segment between <code>(0, 2)</code> and <code>(1, 3)</code> is not inside the shape.</p>
<p><code>box(0, 0, 2, 2).union(box(1, 1, 3, 3)).convex_hull</code>: yes, the convex hull of any shape is convex.</p>
<p><code>Point(0, 0).buffer(1).boundary</code>: no, the boundary is a circle without the inside (approximated by a lot of line segments), and the line segment connecting any two distinct points on the circle is not on the boundary, and in general, the boundary of any shape with strictly positive area is not convex.</p>
<h2 id="Geocoding"><a href="#Geocoding" class="headerlink" title="Geocoding"></a>Geocoding</h2><p><code>geopy</code> provide geocoding services to <strong>convert a text address into a <code>Point</code> geometry</strong> that <strong>specifies the longitude and latitude of the location</strong></p>
<p><code>geopandas.tools.geocode(address)</code> returns a <code>Point</code> object with the coordinate for the address.</p>
<h3 id="Lat-long-CRS"><a href="#Lat-long-CRS" class="headerlink" title="Lat / long CRS"></a>Lat / long CRS</h3><ul>
<li>Long is x-coord</li>
<li>Lat is y-coord<ul>
<li>tells you where the point on Earth is</li>
</ul>
</li>
<li><strong>IMPORTANT</strong>: degrees are not a unit of distance. 1 degree of longitute near the equator is a lot farther than moving 1 degree of longitute near the north pole</li>
</ul>
<p>Using <code>.crs</code> to access CRS of a gdf.</p>
<h4 id="Single-CRS-doesn’t-work-for-the-whole-earth"><a href="#Single-CRS-doesn’t-work-for-the-whole-earth" class="headerlink" title="Single CRS doesn’t work for the whole earth"></a>Single CRS doesn’t work for the whole earth</h4><ul>
<li>Setting a different CRS for Europe that is based on meters.</li>
</ul>
<h1 id="Regex"><a href="#Regex" class="headerlink" title="Regex"></a>Regex</h1><p>Regular Expressions (Regex) is a small language for describing patterns to search for and it is used in many different programming languages</p>
<p>Python <code>re</code> package has <code>re.findall(regex, string)</code> and <code>re.sub(regex, replace, string)</code> to find and replace parts of <code>string</code> using the pattern <code>regex</code>.</p>
<p><code>re.findall(regex, string)</code> return a list</p>
<h2 id="Raw-Strings"><a href="#Raw-Strings" class="headerlink" title="Raw Strings"></a>Raw Strings</h2><p>Python uses escape characters to represent special characters.</p>
<p>Raw strings <code>r&quot;...&quot;</code> starts with <code>r</code> and <strong>do not convert escape characters into special characters</strong>.</p>
<p>It is usually easier to specify regex with raw strings.</p>
<table>
<thead>
<tr>
<th>Code</th>
<th>Character</th>
<th>Note</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>\&quot;</code></td>
<td>double quote</td>
<td>-</td>
</tr>
<tr>
<td><code>\&#39;</code></td>
<td>single quote</td>
<td>-</td>
</tr>
<tr>
<td><code>\\</code></td>
<td>backslash 反斜杠</td>
<td><code>&quot;\\ \&quot; &quot;</code> displays <code>\&quot;</code></td>
</tr>
<tr>
<td><code>\n</code></td>
<td>new line</td>
<td>-</td>
</tr>
<tr>
<td><code>\r</code></td>
<td>carriage return</td>
<td>(not used often)</td>
</tr>
<tr>
<td><code>\t</code></td>
<td>tab “ “</td>
<td>-</td>
</tr>
<tr>
<td><code>\b</code></td>
<td>backspace</td>
<td>(similar to left arrow key)</td>
</tr>
</tbody>
</table>
<p><code>\\</code> 表示转义\后面的符号，这个就是转义\ = \</p>
<p>Raw String Examples</p>
<ul>
<li><code>&quot;\t&quot; == r&quot; &quot;</code> is true.</li>
<li><code>&quot;\\t&quot; == r&quot;\t&quot;</code> is true. </li>
<li><code>&quot;\\\t&quot; == r&quot;\ &quot;</code> is true.</li>
<li><code>&quot;\\\\t&quot; == r&quot;\\t&quot;</code> is true.</li>
<li><code>&quot;A\\B\\C&quot; == r&quot;A\B\C&quot;</code> is true.</li>
</ul>
<h2 id="Meta-Characters"><a href="#Meta-Characters" class="headerlink" title="Meta Characters"></a>Meta Characters</h2><p>Some characters have special functions in a regex, and they are called meta characters.</p>
<table>
<thead>
<tr>
<th>Meta character</th>
<th>Meaning</th>
<th>Example</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>.</code></td>
<td>any character except for <code>\n</code></td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td><code>[]</code></td>
<td>any character inside brackets</td>
<td><code>[abc]</code></td>
<td><code>a</code> or <code>b</code> or <code>c</code></td>
</tr>
<tr>
<td><code>[^ ]</code></td>
<td>any character not inside brackets</td>
<td><code>[^abc]</code></td>
<td>not one of <code>a</code> <code>b</code> <code>c</code></td>
</tr>
<tr>
<td><code>*</code></td>
<td>zero or more of last symbol</td>
<td><code>a*</code></td>
<td>zero or more <code>a</code></td>
</tr>
<tr>
<td><code>+</code></td>
<td>one or more of last symbol</td>
<td><code>a+</code></td>
<td>one or more <code>a</code></td>
</tr>
<tr>
<td><code>?</code></td>
<td>zero or one of last symbol</td>
<td><code>a?</code></td>
<td>zero or one <code>a</code></td>
</tr>
<tr>
<td><code>{ }</code></td>
<td>exact number of last symbol</td>
<td><code>a{3}</code></td>
<td>exactly <code>aaa</code></td>
</tr>
<tr>
<td><code>{ , }</code></td>
<td>number of last symbol in range</td>
<td><code>a{1, 3}</code></td>
<td><code>a</code> or <code>aa</code> or <code>aaa</code></td>
</tr>
<tr>
<td>`</td>
<td>`</td>
<td>either before or after bar</td>
<td>`ab</td>
<td>bc`</td>
<td>either <code>ab</code> or <code>bc</code></td>
</tr>
<tr>
<td><code>\</code></td>
<td>escapes next metacharacter 转义</td>
<td><code>\?</code></td>
<td>literal <code>?</code></td>
</tr>
<tr>
<td><code>^</code></td>
<td>beginning of line</td>
<td><code>^a</code></td>
<td>begins with <code>a</code></td>
</tr>
<tr>
<td><code>$</code></td>
<td>end of line</td>
<td><code>a$</code></td>
<td>ends with <code>a</code></td>
</tr>
</tbody>
</table>
<p><code>*?</code> 非贪婪匹配，匹配到一个就停止</p>
<h2 id="Shorthand"><a href="#Shorthand" class="headerlink" title="Shorthand"></a>Shorthand</h2><p>Some escape characters are used as shorthand.</p>
<table>
<thead>
<tr>
<th>Shorthand</th>
<th>Meaning</th>
<th>Bracket Form</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>\d</code></td>
<td>digit</td>
<td><code>[0-9]</code></td>
</tr>
<tr>
<td><code>\D</code></td>
<td>not digit</td>
<td><code>[^0-9]</code></td>
</tr>
<tr>
<td><code>\w</code></td>
<td>alphanumeric character</td>
<td><code>[a-zA-Z0-9]</code></td>
</tr>
<tr>
<td><code>\W</code></td>
<td>not alphanumeric character</td>
<td><code>[^a-zA-Z0-9]</code></td>
</tr>
<tr>
<td><code>\s</code></td>
<td>white space</td>
<td><code>[\t\n\r]</code></td>
</tr>
<tr>
<td><code>\S</code></td>
<td>not white space</td>
<td><code>[^\t\n\r]</code></td>
</tr>
</tbody>
</table>
<h2 id="Capture-Group"><a href="#Capture-Group" class="headerlink" title="Capture Group"></a>Capture Group</h2><p><code>re.findall</code> can return a list of substrings or list of tuples of substrings using capturing groups inside <code>(...)</code>, for example, the regex <code>...(x)...(y)...(z)...</code> returns a list of tuples with three elements matching <code>x</code>, <code>y</code>, <code>z</code>. using<code>((x),(y))</code> , return <code>[(xy,x,y)]</code></p>
<p><code>re.sub</code> can replaces the matches by another string, the captured groups can be used in the replacement string by <code>\g&lt;1&gt;</code>, <code>\g&lt;2&gt;</code>, <code>\g&lt;3&gt;</code>, …, for example, replace <code>...(x)...(y)...(z)...</code> by <code>\g&lt;2&gt;\g&lt;3&gt;\g&lt;1&gt;</code> will return <code>yzx</code>. </p>
<p>最外面的括号表示第一个是整体</p>
<h1 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h1><h2 id="Feature-Representation"><a href="#Feature-Representation" class="headerlink" title="Feature Representation"></a>Feature Representation</h2><p>Items need to be represented by vector of numbers, item i is $\left(x_{i1}, x_{i2}, …, x_{im}\right)$.</p>
<p>Some features are already represented by real numbers, sometimes need to be rescaled to [0,1].</p>
<p>Some features are categories, could be converted using one-hot encoding.</p>
<p><strong>Images features and text features require additional preprocessing</strong>.</p>
<h2 id="Text"><a href="#Text" class="headerlink" title="Text"></a>Text</h2><h3 id="Tokenization"><a href="#Tokenization" class="headerlink" title="Tokenization"></a>Tokenization</h3><p>A text document needs to <strong>be split into words.</strong></p>
<p>Split the string by <strong>space and punctuation</strong>, sometimes regular expression rules can be used.</p>
<p><strong>Remove stop words: “the”, “of”, “a”, “with”, …</strong></p>
<p>Stemming and lemmatization: “looks”, “looked”, “looking” to “look”.</p>
<p><code>nltk</code> has functions to do these. For example, <code>nltk.corpus.stopwords.words(&quot;english&quot;)</code> to get a list of stop words in English, and <code>nltk.stem.WordNetLemmatizer().lemmatize(word)</code> to lemmatize the token <code>word</code>.</p>
<h3 id="Vocabulary"><a href="#Vocabulary" class="headerlink" title="Vocabulary"></a>Vocabulary</h3><p>A word token is an occurrence of a word.</p>
<p>A word type is a unique word as a dictionary entry.</p>
<p>A vocabulary is a list of word types, typically 10000 or more word types. Sometimes <code>&lt;s&gt;</code> (start of sentence), <code>&lt;/s&gt;</code> (end of sentence), and <code>&lt;unk&gt;</code> (out of vocabulary words) are included in the vocabulary.</p>
<p>A corpus is a larger collection of text (like a <code>DataFrame</code>).</p>
<p>A document is a unit of text item (like a row in a <code>DataFrame</code>).</p>
<h3 id="Bag-of-Words-Features"><a href="#Bag-of-Words-Features" class="headerlink" title="Bag of Words Features"></a>Bag of Words Features</h3><p><code>sklearn.feature_extraction.text.CountVectorizer</code> can be used to convert text documents to a bag of words matrix</p>
<p><code>sklearn.feature_extraction.text.TfidfVectorizer</code> can be used to convert text documents to a bag of words matrix</p>
<p>Bag of words features represent <strong>documents as an unordered collection of words</strong>.</p>
<p>Each document is represented by a row containing the number of occurrences of each word type in the vocabulary.</p>
<p>For word type j and document i, the feature is $c\left(i, j\right)$ the number of times word j appears in document i.</p>
<h3 id="TF-IDF-Features"><a href="#TF-IDF-Features" class="headerlink" title="TF-IDF Features"></a>TF-IDF Features</h3><p>TF-IDF or Term Frequency Inverse Document Frequency features adjust for the fact that some words appear more frequently in all documents</p>
<p>The term frequency of word type j in document i is defined as $\text{tf} \left(i, j\right) = \dfrac{c\left(i, j\right)}{\displaystyle\sum_{j’} c\left(i, j’\right)}$ where $c\left(i, j\right)$ is the number of times word j appears in document i, and $\displaystyle\sum_{j’} c\left(i, j’\right)$ is the total number of words in document i.</p>
<p>The inverse document frequency of word type j in document i is defined as $\text{idf} \left(i, j\right) = \log \left(\dfrac{n + 1}{n\left(j\right) + 1}\right)$ where $n\left(j\right)$ is the number of documents containing word j, and n is the total number of documents.</p>
<p>For word type j and document i, the feature is $\text{tf} \left(i, j\right) \cdot \text{idf} \left(i, j\right)$.</p>
<h2 id="Images"><a href="#Images" class="headerlink" title="Images"></a>Images</h2><p>Image Pixel Intensity Features</p>
<p>Gray scale images have pixels valued from 0 to 255 (integers, 0 being black, 255 being white), or from 0 to 1 (real values, 0 being black, 1 being white).</p>
<p>These pixel values are called pixel intensities.</p>
<p>The pixel value matrices can be flattened into a vector (i.e. k pixel by k pixel image can be written as a list of k^2 numbers and used as input features.</p>
<p><code>scikit-image</code> can be used for basic image processing tasks</p>
<p><code>skimage.io.imread</code> (read image from file), <code>skimage.io.imshow</code> (show image)</p>
<p>The images are stored as <code>numpy.array</code>, which can be flattened using <code>numpy.ndarray.flatten</code></p>
<h3 id="Color-Images"><a href="#Color-Images" class="headerlink" title="Color Images"></a>Color Images</h3><p>RGB color images have color pixels represented by three numbers Red, Green, Blue, each valued from 0 to 255 or 0 to 1.</p>
<p>Intensity can be computed as $I = \dfrac{1}{3} \left(R + G + B\right)$.</p>
<p>Other perceptual luminance-preserving conversion can be done too, for example $I = 0.2125 R + 0.7154 G + 0.0721 B$.</p>
<p><code>skimage.color.rgb2gray</code> (convert into gray-scale)</p>
<p>The pixel value 3D arrays can be converted into pixel intensity matrices and flattened into a feature vector.</p>
<h3 id="Convolution"><a href="#Convolution" class="headerlink" title="Convolution"></a>Convolution</h3><p>Convolution between an image and a filter (sometimes called kernel) is the dot product of every region of an image and the filter (sometimes flipped).</p>
<p><strong>Convolution with special filters detects special features.</strong></p>
<p><code>skimage.filters</code> has a list of special filters</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Example</th>
<th>Use</th>
</tr>
</thead>
<tbody>
<tr>
<td>Identity</td>
<td><strong>$\begin{bmatrix} 0 &amp; 0 &amp; 0 \ 0 &amp; 1 &amp; 0 \ 0 &amp; 0 &amp; 0 \end{bmatrix}$</strong></td>
<td>nothing</td>
</tr>
<tr>
<td>Gaussian</td>
<td>$\begin{bmatrix} 0.0625 &amp; 0.125 &amp; 0.0625 \ 0.125 &amp; 0.25 &amp; 0.125 \ 0.0625 &amp; 0.125 &amp; 0.0625 \end{bmatrix}$</td>
<td>blur</td>
</tr>
<tr>
<td>X gradient</td>
<td>$\begin{bmatrix} 0 &amp; 0 &amp; 0 \ 1 &amp; 0 &amp; -1 \ 0 &amp; 0 &amp; 0 \end{bmatrix}$</td>
<td>vertical edges</td>
</tr>
<tr>
<td>Left (Right) Sobel</td>
<td>$\begin{bmatrix} 1 &amp; 0 &amp; -1 \ 2 &amp; 0 &amp; -2 \ 1 &amp; 0 &amp; -1 \end{bmatrix}$</td>
<td>vertical edges (blurred)</td>
</tr>
<tr>
<td>Y gradient</td>
<td>$\begin{bmatrix} 0 &amp; 1 &amp; 0 \ 0 &amp; 0 &amp; 0 \ 0 &amp; -1 &amp; 0 \end{bmatrix}$</td>
<td>vertical edges</td>
</tr>
<tr>
<td>Top (Bottom) Sobel</td>
<td>$\begin{bmatrix} 1 &amp; 2 &amp; 1 \ 0 &amp; 0 &amp; 0 \ -1 &amp; -2 &amp; -1 \end{bmatrix}$</td>
<td>vertical edges (blurred)</td>
</tr>
</tbody>
</table>
<h1 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h1><p>Supervised learning (data is labeled): use the data to figure out the relationship between the features and labels of the items, and apply the relationship to predict the label of a new item.</p>
<p>If the labels are discrete (categories): classification.</p>
<p>If the labels are continuous: regression.</p>
<h2 id="Binary-Classification"><a href="#Binary-Classification" class="headerlink" title="Binary Classification"></a>Binary Classification</h2><p>For binary classification, the labels are binary, either 0 or 1, but the output of the classifier $\hat{f}(x)$ can be a number between 0 and 1.</p>
<p> $\hat{f}(x)$ usually represents the probability that the label is 1, and it is sometimes called the activation value.</p>
<p> If a deterministic prediction $\hat{y}$ is required, it is usually set to $\hat{y}=0$ if $\hat{f}(x) \leq 0.5 $and $\hat{y}=1$ if  $\hat{f}(x) \gt 0.5 $.</p>
<table>
<thead>
<tr>
<th>Item</th>
<th>Input (Features)</th>
<th>Output (Labels)</th>
<th>-</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>$(x_{11},x_{12},…,x_{1m})$</td>
<td>$y_1∈{0,1}$</td>
<td>training data</td>
</tr>
<tr>
<td>2</td>
<td>$(x_{21},x_{22},…,x_{2m})$</td>
<td>$y_2∈{0,1}$</td>
<td>-</td>
</tr>
<tr>
<td>3</td>
<td>$(x_{31},x_{32},…,x_{3m})$</td>
<td>$y_3∈{0,1}$</td>
<td>-</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
<tr>
<td>n</td>
<td>$(x_{n1},x_{n2},…,x_{nm})$</td>
<td>$y_n∈{0,1}$</td>
<td>used to figure out $y \approx \hat{f}(x)$</td>
</tr>
<tr>
<td>new</td>
<td>$(x_1’,x_2’,…,x_m’)$</td>
<td>$y’ \in [0,1]$</td>
<td>guess $y’=1$ with probability $\hat{f}(x)$</td>
</tr>
</tbody>
</table>
<h2 id="Confusion-Matrix"><a href="#Confusion-Matrix" class="headerlink" title="Confusion Matrix"></a>Confusion Matrix</h2><p>(1) number of item labeled 1 and predicted to be 1 (true positive: TP),<br>(2) number of item labeled 1 and predicted to be 0 (false negative: FN),<br>(3) number of item labeled 0 and predicted to be 1 (false positive: FP),<br>(4) number of item labeled 0 and predicted to be 0 (true negative: TN).</p>
<table>
<thead>
<tr>
<th>Count</th>
<th>Predict 1</th>
<th>Predict 0</th>
</tr>
</thead>
<tbody>
<tr>
<td>Label 1</td>
<td>TP</td>
<td>FN</td>
</tr>
<tr>
<td>Label 0</td>
<td>FP</td>
<td>TN</td>
</tr>
</tbody>
</table>
<p>Precision is the positive predictive value, or $\frac{TP}{TP+FP}$.<br>➭ Recall is the true positive rate, or $\frac{TP}{TP+FN}$.<br>➭ F-measure (or F1 score) is $2·\frac{pr}{p+r} $, where p is the precision and r is the recall</p>
<h2 id="Multi-class-Classification"><a href="#Multi-class-Classification" class="headerlink" title="Multi-class Classification"></a>Multi-class Classification</h2><p>Multi-class classification is different from regression since the classes are not ordered.</p>
<p> Three approaches are used:<br>(1) Directly <strong>predict the probability of each class.</strong><br>(2) <strong>One-vs-one</strong> classifiers.<br>(3) <strong>One-vs-all</strong> (One-vs-rest) classifiers.</p>
<h3 id="Class-Probabilities"><a href="#Class-Probabilities" class="headerlink" title="Class Probabilities"></a>Class Probabilities</h3><p>If there are k classes, the classifier could output k numbers between 0 and 1, and sum up to 1, to represent the probability that the item belongs to each class, sometimes called activation values.</p>
<p>If a deterministic prediction is required, the classifier can predict the label with the largest probability.</p>
<h3 id="One-vs-one-Classifiers"><a href="#One-vs-one-Classifiers" class="headerlink" title="One-vs-one Classifiers"></a>One-vs-one Classifiers</h3><p>If there are j classes, then $1/2k(k-1)$ binary classifiers will be trained, 1 vs 2, 1 vs 3, 2 vs 3, …</p>
<p>The prediction can be the label that receives the largest number of votes from the one-vs-one binary classifiers.</p>
<h3 id="One-vs-all-Classifiers"><a href="#One-vs-all-Classifiers" class="headerlink" title="One-vs-all Classifiers"></a>One-vs-all Classifiers</h3><p>If there are k classes, then k binary classifiers will be trained, 1 vs not 1, 2 vs not 2, 3 vs not 3, …</p>
<p>The prediction can be the label that achieves the largest probability in the one-vs-all binary classifiers.</p>
<p><strong>Multi-class Confusion Matrix</strong></p>
<p>前面的是行，后面是列</p>
<p>precision of class i is $\frac{c_{ii}}{\sum_j c_{ji}}$(列相同), and recall of class i is $\frac{c_{ii}}{\sum_j c_{ij}}$(行相同).</p>
<h3 id="Conversion-from-Probabilities-to-Predictions"><a href="#Conversion-from-Probabilities-to-Predictions" class="headerlink" title="Conversion from Probabilities to Predictions"></a>Conversion from Probabilities to Predictions</h3><p>Probability predictions are given in a matrix, where row i is the probability prediction for item i, and column j is the predicted probability that item i has label j.</p>
<p><strong><code>argmax</code>返回index！！！！！！</strong></p>
<p>Given an n×m probability prediction matrix <code>p</code>, <code>p.max(axis = 1)</code> computes the n×1 vector of maximum probabilities, one for each row, and <code>p.argmax(axis = 1)</code> computes the column indices of those maximum probabilities, which also corresponds to the predicted labels of the items.</p>
<p>For example, if <code>p</code> is $\begin{bmatrix} 0.1      &amp; 0.2 &amp; 0.7  \ 0.8     &amp; 0.1 &amp; 0.1 \ 0.4     &amp; 0.5 &amp; 0.1 \ \end{bmatrix}$ , then <code>p.max(axis = 1)</code> is $\begin{bmatrix} 0.7 \ 0.8     \ 0.5\ \end{bmatrix}$ and <code>p.argmax(axis = 1)</code> is $\begin{bmatrix} 2 \ 0     \ 1 \ \end{bmatrix}$ </p>
<p>Note: <code>p.max(axis = 0)</code> and <code>p.argmax(axis = 0)</code> would compute max and argmax along the columns.</p>
<p><strong>ps:</strong> Pixel intensity usually uses the convention that 0 means black and 1 means white, as done in <code>matplotlib.imshow</code> and <code>skimage.imshow</code>, unlike the example from the previous lecture.</p>
<h2 id="Linear-Classifiers"><a href="#Linear-Classifiers" class="headerlink" title="Linear Classifiers"></a>Linear Classifiers</h2><p> A classifier is linear if the decision boundary is linear (line in 2D, plane in 3D, hyperplane in higher dimensions).</p>
<p>Points above the plane (in the direction of the normal of the plane) are predicted as 1, and points below the plane are predicted as 0.</p>
<p>A set of linear coefficients, usually estimated based on the training data, called weights, $w_1,w_2,…,w_m$, and a bias term b, so that the classifier can be written in the form $\hat{y}=1$  if $w_1x_1’+w_2x_2’+…+w_mx_n’+b \geq 0$ and  $\hat{y}=0$  if $w_1x_1’+w_2x_2’+…+w_mx_n’+b &lt;0$</p>
<ul>
<li>Linear threshold unit (LTU) perceptron: $g(z)=1$ if $z&gt;0$ and $g(z)=0$ otherwise.</li>
<li>Logistic regression: $g(z)=\frac{1}{1+e^{-z}}$</li>
<li>Support vector machine (SVM): $g(z)=1$ if $z&gt;0$ and $g(z)=0$ otherwise, but with a different method to find the weights (that maximizes the separation between the two classes).</li>
</ul>
<p>Nearest neighbors and decision trees have piecewise linear decision boundaries and is usually not considered linear classifiers.</p>
<p>Note: Naive Bayes classifiers are not always linear under general distribution assumptions.</p>
<h3 id="Activation-Function"><a href="#Activation-Function" class="headerlink" title="Activation Function"></a>Activation Function</h3><p>Sometimes, if a probabilistic prediction is needed, $\hat{f}(x’)=g(w_1x_1’+w_2x_2’+…+w_mx_m’+b)$ outputs a number between 0 and 1, and the classifier can be written in the form $\hat{y}=1$ if $\hat{f}(x’) \geq 0.5$ and $\hat{y}=0$ if $\hat{f}(x’) &lt; 0.5$ .</p>
<p>The function $g$ can be any non-linear function, the resulting classifier is still linear.</p>
<h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><p>Logistic regression is usually used for classification, not regression.</p>
<p>The function $g(z)=\frac{1}{1+e^{-z}}$ is called the <strong>logistic activation function (or sigmoid function)</strong>. (z can use $x‘@w+b$)</p>
<p> How well the weights fit the training data is measured by a loss (or cost) function, which is the sum over the loss from each training item $C(w)=C_1(w)+C_2(w)+…+C_n(w)$, and for logistic regression, $C_i(w)=-y_ilog{g(z_i)}-(1-y_i)log(1-g(z_i)),z_i=w_1x_{i1}+w_2x_{i2}+…+w_mx_{im}+b$, called the <strong>cross-entropy loss</strong></p>
<p>x@y：矩阵乘法</p>
<p>Classifier的predict都需要一个不等式来划分不同的class</p>
<h3 id="Interpretation-of-Coefficients"><a href="#Interpretation-of-Coefficients" class="headerlink" title="Interpretation of Coefficients"></a>Interpretation of Coefficients</h3><p>The weight $w_j$ in front of feature j can be interpreted <strong>as the increase in the log-odds</strong> of the label y being 1, associated with the increase of 1 unit in $x_j$, holding all other variables constant.</p>
<p>This means, if the feature $x_j’$ increases by 1, then the odds of y being 1 is increased by $e^{w_j}$.</p>
<p>The bias b is the log-odds of y being 1, when $x_1’=x_2’=…=x_m’=0$.</p>
<h2 id="Nonlinear-Classifiers"><a href="#Nonlinear-Classifiers" class="headerlink" title="Nonlinear Classifiers"></a>Nonlinear Classifiers</h2><p>Non-linear classifiers are classifiers with non-linear decision boundaries.</p>
<p>Non-linear models are difficult to estimate directly in general.</p>
<p>Two ways of creating non-linear classifiers are,<br>(1) <strong>Non-linear transformations of the features</strong> (for example, kernel support vector machine)<br>(2) <strong>Combining multiple copies of linear classifiers</strong> (for example, neural network, decision tree)</p>
<h3 id="Sklearn"><a href="#Sklearn" class="headerlink" title="Sklearn"></a>Sklearn</h3><p> New features can be constructed manually, or through using transformers provided by <code>sklearn</code> in a <code>sklearn.Pipeline</code>.</p>
<p><strong>A categorical column</strong> can be converted to <strong>multiple columns</strong> using <code>sklearn.preprocessing.OneHotEncoder</code> </p>
<p><code>OneHotEncoder</code>: Used for categorical variables with discrete values. It converts categorical variables into a binary vector representation, which is not applicable to numerical columns.</p>
<p><code>(OneHotEncoder(), [&quot;c1&quot;]</code> applied to the categorical column <code>c1</code> : x cols -&gt; x cols</p>
<p>A numerical column <strong>can normalized to center at 0 with variance 1</strong> using <code>sklearn.preprocessing.StandardScaler</code></p>
<p><code>StandardScaler</code> is used to scale numerical features to have mean 0 and variance 1, <strong>which helps in standardizing the numerical features</strong>. Logistic Regression, like many other machine learning algorithms, can benefit from having features on the same scale as it aids in convergence and prevents certain features from dominating due to their larger magnitudes.</p>
<p>Additional columns including <strong>powers of one column</strong> can be added using <code>(sklearn.preprocessing.PolynomialFeatures,[&quot;c2&quot;])</code></p>
<p> <code>PolynomialFeatures</code>: This is used to create higher-degree polynomial combinations of input features. While it might be useful in some cases to capture nonlinear relationships in data</p>
<p><code>PolynomialFeatures(degree=2, include_bias=False)</code> applied to the numerical column <code>c2</code></p>
<p>怎么算根据cols数量确定变量个数 如2 cols = a,b, degree jueding 次方数，逐渐累计，算有多少种组合方式</p>
<p><code>include_bias=TURE</code> 就+1</p>
<p>Bag of words features can TF-IDF features can be added using <code>feature_extraction.text.CountVectorizer</code> and <code>feature_extraction.text.TfidfVectorizer</code>.</p>
<h3 id="Kernel-Trick"><a href="#Kernel-Trick" class="headerlink" title="Kernel Trick"></a>Kernel Trick</h3><p><code>sklearn.svm.SVC</code> can be used to train kernel SVMs, possibly infinite number of new features, efficiently through dual optimization (more detail about this in the Linear Programming lecture)</p>
<p>Available kernel functions include: <code>linear</code> (no new features), <code>polynomial</code> (degree d polynomial features), <code>rbf</code> (Radial Basis Function, infinite number of new features).</p>
<h2 id="Neural-Network"><a href="#Neural-Network" class="headerlink" title="Neural Network"></a>Neural Network</h2><p>Neural networks (also called multilayer perceptron) can be viewed as <strong>multiple layers of logistic regressions</strong> (or perceptrons with other activation functions).</p>
<p>The outputs of the previous layers are used as the inputs in the next layer.</p>
<p>The layers in between the inputs x and output y are <strong>hidden layers</strong> and can be viewed as additional internal features generated by the neural network.</p>
<p><code>sklearn.neural_network.MLPClassifier</code> can be used to train fully connect neural networks without convolutional layers or transformer modules. The activation functions <code>logistic</code>, <code>tanh</code>, and <code>relu</code> can be used</p>
<p> <code>PyTorch</code> is a popular package for training more general neural networks with special layers and modules, and with custom activation functions:</p>
<h2 id="Model-Selection"><a href="#Model-Selection" class="headerlink" title="Model Selection"></a>Model Selection</h2><p>Many non-linear classifiers can overfit the training data perfectly</p>
<p>Comparing prediction accuracy of these classifiers on the training set is not meaningful.</p>
<p>Cross validation can be used to compare and select classifiers with different parameters, for example, the neural network architecture, activation functions, or other training parameters.</p>
<p>The dataset is split into K subsets, called <strong>K folds</strong>, and each fold is used as the test set while the <strong>remaining K - 1 folds are used to train.</strong></p>
<p>The average accuracy from the K folds can be used as a measure of the classification accuracy on the training set.</p>
<p>If $k=n$, then there is only one item in each fold, and the cross validation procedure in this case is called <strong>Leave-One-Out Cross Validation (LOOCV)</strong>.</p>
<p><strong>Cross Validation:</strong> compare a neural network with two hidden layers and an RBF kernel SVM on a simple 2D dataset using cross validation accuracy.</p>
<p> In a neural network with 4 input features, 3 units in the first hidden layer, 2 units in the second hidden layer, and 1 unit for binary classification in the output layer, how many weights and biases does the network have?</p>
<p>Suppose the activation functions are logistic (other activation functions do not change the answer to this questions), then:<br>(1) In the first layer, there are 3 logistic regressions with 4 features, meaning there are 12 weights and 3 biases.<br>(2) In the second layer, there are 2 logistic regressions with 3 features (3 units from the previous layer), meaning there are 6 weights and 2 biases.<br>(3) In the last layer, there is 1 logistic regression with 2 features (2 units from the previous layer), meaning there are 2 weights and 1 bias.</p>
<p>Therefore, there are 12 + 6 + 1 = 19 weights and 3 + 2 + 1 = 6 biases in the network.</p>
<p>Weights: </p>
<ul>
<li>Between Input and First Hidden Layer: Number of weights = <strong>(number of input features) * (number of neurons in the first hidden layer)</strong></li>
<li>Between First Hidden and Second Hidden Layer: Number of weights = <strong>(number of neurons in the first hidden layer) * (number of neurons in the second hidden layer)</strong></li>
<li>Between Second Hidden Layer and Output Layer: Number of weights = <strong>(number of neurons in the second hidden layer) * (number of output neurons)</strong></li>
</ul>
<p>Biases: One bias term is associated with <strong>each neuron</strong> in the hidden layers and the output layer, except for the input layer which doesn’t have biases.</p>
<h2 id="Linear-Algebra"><a href="#Linear-Algebra" class="headerlink" title="Linear Algebra"></a>Linear Algebra</h2><h3 id="Least-Squares-Regression"><a href="#Least-Squares-Regression" class="headerlink" title="Least Squares Regression"></a>Least Squares Regression</h3><p>If the label y is continuous, it can still be predicted using  $\hat{f}(x’)=w_1x_1’+w_2x_2’+…+w_mx_m’+b$.</p>
<p><code>scipy.linalg.lstsq(x, y)</code> can be used to find the weights w and the bias n</p>
<p>It computes the least-squares solution to $Xw=y$, or the w such that $||y-Xw||=\sum_{i=1}^n(y_i-w_1x_{i1}-w_2x_{i2}-…-w_mx_{im}-b)^2$ is minimized.</p>
<p> <code>sklearn.linear_model.LinearRegression</code> performs the same linear regression.</p>
<h3 id="Design-Matrix"><a href="#Design-Matrix" class="headerlink" title="Design Matrix"></a>Design Matrix</h3><p>$X$ is a matrix with n rows and m+1 columns, called the design matrix, where each row of $X$ is a list of features of a training item plus a 1 at the end, meaning row i of $X$ is $(x_{i1},x_{i2},…,x_{im},1)$.</p>
<p>The transpose of $X$ , denoted by $X^T$ , flips the matrix over its diagonal, which means each column of $X^T$ is a training item with a 1 at the bottom.</p>
<h3 id="Matrix-Inversion"><a href="#Matrix-Inversion" class="headerlink" title="Matrix Inversion"></a>Matrix Inversion</h3><p>$Xw=y$ can be solved using $w=y/X$ (not proper notation) or $w=X^{-1}y$ only if $X$ is square and invertible.</p>
<p>$X$ has n rows and m columns so it is usually not square and thus not invertible.</p>
<p>$X^tX$ as M+1 rows and M+1 columns and is invertible if $X$ has linearly independent columns (the features are not linearly related)</p>
<p>$X^TXw=X^Ty$ is used, which can be solved as $w=(X^TX)^{-1}(X^Ty)$.</p>
<p><code>scipy.linalg.inv(A)</code> can be used to compute the inverse of <code>A</code></p>
<p><code>scipy.linalg.solve(A, b)</code> can be used to solve for $w$ in $Aw=b$ and is faster than computing the inverse</p>
<p>To solve $Aw=b$, $Aw=c$ for square invertible $A$</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Procedure</th>
<th>Speed comparison</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td><code>inv(A) @ b</code> then <code>inv(A) @ c</code></td>
<td>Slow</td>
</tr>
<tr>
<td>2</td>
<td><code>solve(A, b)</code> then <code>solve(A, c)</code></td>
<td>Fast</td>
</tr>
<tr>
<td>3</td>
<td><code>lu, p = lu_factor(A)</code> then <code>lu_solve((lu, p), b)</code> then <code>lu_solve((lu, p), c)</code></td>
<td>Faster</td>
</tr>
</tbody>
</table>
<p> When $A=X^TX$ and $b=X^Ty$, solving $Aw=b$ leads to the solution to the linear regression problem. If the same features are used to make predictions for different prediction variables, it is faster to use <code>lu_solve</code>.</p>
<h3 id="Numerical-Instability"><a href="#Numerical-Instability" class="headerlink" title="Numerical Instability"></a>Numerical Instability</h3><p>Division by a small number close to 0 <strong>may lead to inaccurate answers</strong>.</p>
<p>I<strong>nverting or solving a matrix close to 0</strong> could lead to inaccurate solutions too.</p>
<p>A matrix being close to 0 is usually defined by its condition number, not determinant.</p>
<p> <code>numpy.linalg.cond</code> can be used find the condition number</p>
<p> Larger condition number means the solution can more inaccurate.</p>
<h3 id="Multicollinearity"><a href="#Multicollinearity" class="headerlink" title="Multicollinearity"></a>Multicollinearity</h3><p>In linear regression, large condition number of the design matrix is related to multicollinearity.</p>
<p>Multicollinearity occurs when <strong>multiple features are highly linearly correlated</strong>.</p>
<p>One simple rule of thumb is that the regression has multicollinearity if the condition number of larger than 30.</p>
<h2 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h2><h3 id="Loss-Function-and-R-Squared"><a href="#Loss-Function-and-R-Squared" class="headerlink" title="Loss Function and R Squared"></a>Loss Function and R Squared</h3><p> R squared, or coefficient of determination, $R^2$ is the fraction of the variation of y that can be explained by the variation of x.</p>
<p>The formula for computing R squared is:  $R^{2} = 1 - \dfrac{\displaystyle\sum_{i=1}^{n} \left(y_{i} - \hat{y}<em>{i}\right)^{2}}{\displaystyle\sum</em>{i=1}^{n} \left(y_{i} - \overline{y}\right)^{2}}$ or $R^{2} = 1 - \dfrac{\displaystyle\sum_{i=1}^{n} \left(y_{i} - \hat{y}<em>{i}\right)^{2}}{\displaystyle\sum</em>{i=1}^{n} \left(y_{i} - \overline{y}\right)^{2}}$  where $y_i$ is the true value of the output (label) of item $i,\hat{y_i}$ is the predicted value, and $\overline{y}$ is the average value.</p>
<p> Since R squared increase as the number of features increase, it is not a good measure of fitness, and sometimes adjusted R squared is used: $\overline{R}^{2} = 1 - \left(1 - R^{2}\right) \dfrac{n - 1}{n - m - 1}$</p>
<p>R 范围：$[-\inf , 1]$</p>
<p><strong>If <code>model</code> is a <code>sklearn.linear_model.LinearRegression</code>, then <code>model.score(x, y)</code> will compute the $R^2$ on the training set x,y.</strong></p>
<h3 id="Continuous-Features"><a href="#Continuous-Features" class="headerlink" title="Continuous Features"></a>Continuous Features</h3><p>If a feature is continuous, then <strong>l</strong> in the output if the feature changes by 1 unit, holding every other feature constant.</p>
<p>Similar to the kernel trick and polynomial features for classification, polynomial features can be added using <code>sklearn.preprocessing.PolynomialFeatures(degree = n)</code>. Note that the interaction terms are added as well, for example, if there are two columns $x_{1}, x_{2}$, then the columns that will be added when <code>degree = 2</code> are $1, x_{1}, x_{2}, x_{1}^{2}, x_{2}^{2}, x_{1} x_{2}$</p>
<h3 id="Discrete-Features"><a href="#Discrete-Features" class="headerlink" title="Discrete Features"></a>Discrete Features</h3><p>Discrete features are converted using one hot encoding.</p>
<p>One of the categories should be treated as the base category, since if all categories are included, the design matrix will not be invertible: <code>sklearn.preprocessing.OneHotEncoder(drop = &quot;first&quot;)</code> could be used to add the one hot encoding columns excluding the first category.</p>
<p>The weight (coefficient) of $1_{x_{j} = k}$ represents the expected change in the output if the feature j is in the category k instead of the base class.</p>
<h3 id="Log-Transforms-of-Features"><a href="#Log-Transforms-of-Features" class="headerlink" title="Log Transforms of Features"></a>Log Transforms of Features</h3><p>Log transformations can be used on the features too.</p>
<p>The weight (coefficient) of $\log\left(x_{j}\right)$ represents the expected change in the output if the feature is increased by 1 percent.</p>
<p>If $\log\left(y\right)$ is used in place of y, then weights represent the percentage change in y due to a change in the feature. </p>
<h1 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h1><h2 id="Gradient"><a href="#Gradient" class="headerlink" title="Gradient"></a>Gradient</h2><h3 id="Loss-Minimization"><a href="#Loss-Minimization" class="headerlink" title="Loss Minimization"></a>Loss Minimization</h3><p>Logistic regression, neural network, and linear regression compute the best weights and biases by solving an optimization problem: $\displaystyle\min_{w,b} C\left(w, b\right)$ where C is the loss (cost) function that measures the amount of error the model is making.</p>
<p>The search strategy is to <strong>start with a random set of weights and biases</strong> and iteratively move to another set of weights and biases with a lower loss.</p>
<h3 id="Nelder-Mead"><a href="#Nelder-Mead" class="headerlink" title="Nelder Mead"></a>Nelder Mead</h3><p>Nelder Mead method (downhill simplex method) is a <strong>derivative-free method that only requires the knowledge of the objective function</strong>, and not its derivatives.</p>
<p>Start with a random simplex: a line in 1D, a triangle in 2D, a tetrahedron (triangular pyramid) in 3D, …, a polytope with n+1 vertices in nD.</p>
<p>In every iteration, <strong>replace the worst point</strong> (the one with the largest loss among the n+1 vertices), by <strong>its reflection through the centriod of the remaining n points</strong>.</p>
<p>If the new point is better than the original point, expand the simplex; if the new point is worse than the original point, shrink the simplex.</p>
<h3 id="Derivatives"><a href="#Derivatives" class="headerlink" title="Derivatives"></a>Derivatives</h3><p>For a single-variable function $C\left(w\right)$, if the derivative at $C’\left(w\right)$, is positive then decreasing w would decrease $C\left(w\right)$, and if the derivative at w is negative then increasing w would decrease $C\left(w\right)$.</p>
<p>In general, $w = w - \alpha C’\left(w\right)$ would update w to decrease $C(w)$ by the largest amount.</p>
<h3 id="Gradient-1"><a href="#Gradient-1" class="headerlink" title="Gradient"></a>Gradient</h3><p>If there are more than one features, the vector of derivatives, one for each weight, is called the gradient vector, denoted by $\begin{bmatrix} \dfrac{\partial C}{\partial w_{1}} \ \dfrac{\partial C}{\partial w_{2}} \ … \ \dfrac{\partial C}{\partial w_{m}} \end{bmatrix}$ pronounced as “the gradient of C with respect to w” or “D w C” (not “Delta w C”).</p>
<p>The gradient vector represent rate and direction of the fastest change.</p>
<p>$w = w - \alpha \nabla_{w} C$ is called gradient descent and would update w to decrease $C\left(w\right)$ by the largest amount.</p>
<p>The $\alpha$ in $w = w - \alpha \nabla_{w} C$ is called the learning rate and determines how large each gradient descent step will be.<br>➭ The learning rate can be constant, for example, $\alpha$=1, $\alpha$=0.1, or $\alpha$=0.01; or decreasing, $\alpha = \dfrac{1}{t}$ , $\alpha = \dfrac{0.1}{t}$, or $\alpha = \dfrac{1}{\sqrt{t}}$ in iteration t, and they can be adaptive based on the gradient of previous iterations or the second derivative (Newton’s method).</p>
<h3 id="Newton’s-Method"><a href="#Newton’s-Method" class="headerlink" title="Newton’s Method"></a>Newton’s Method</h3><p>$\nabla^{2}<em>{w} C =\begin{bmatrix} \dfrac{\partial^2 C}{\partial w</em>{1}^2} &amp; \dfrac{\partial C}{\partial w_{1} \partial w_{2}} &amp; … &amp; \dfrac{\partial C}{\partial w_{1} \partial w_{m}} \ \dfrac{\partial C}{\partial w_{2} \partial w_{1}} &amp; \dfrac{\partial^2 C}{\partial w_{2}^2} &amp; … &amp; \dfrac{\partial C}{\partial w_{2} \partial w_{m}} \ … &amp; … &amp; … &amp; … \ \dfrac{\partial C}{\partial w_{m} \partial w_{1}} &amp; \dfrac{\partial C}{\partial w_{m}} \left(w_{2}\right) &amp; … &amp; \dfrac{\partial^2 C}{\partial w_{m}^2} \end{bmatrix}$</p>
<p>It can be used compute the step size adaptively, but it is usually too costly to compute and invert the Hessian matrix.</p>
<p>Newton’s method use the iterative update formula: $w = w - \alpha \left[\nabla^{2}<em>{w} C\right]^{-1} \nabla</em>{w} C$.</p>
<h3 id="Broyden–Fletcher–Goldfarb–Shanno-BFGS-Method"><a href="#Broyden–Fletcher–Goldfarb–Shanno-BFGS-Method" class="headerlink" title="Broyden–Fletcher–Goldfarb–Shanno (BFGS) Method"></a>Broyden–Fletcher–Goldfarb–Shanno (BFGS) Method</h3><p>To avoid computing and approximating the Hessian matrix, BFGS uses gradient from the previous step to approximate the inverse of the Hessian, and perform line search to find the step size.</p>
<p>This method is a quasi-Newton method, and does not require specifying the Hessian matrix.</p>
<h3 id="Scipy-Optimization-Function"><a href="#Scipy-Optimization-Function" class="headerlink" title="Scipy Optimization Function"></a>Scipy Optimization Function</h3><p><code>scipy.optimize.minimize(f, x0)</code> <strong>minimizes the function <code>f</code> with initial guess <code>x0</code></strong>, and the methods include derivative-free methods such as <code>Nelder-Mead</code>, gradient methods such as <code>BFGS</code> (need to specify the gradient as the <code>jac</code> parameter, Jacobian matrix whose rows are gradient vectors), and methods that use Hessian such as <code>Newton-CG</code> (CG stands for conjugate gradient, a way to approximately compute $\left[\nabla^{2}<em>{w} C\right]^{-1} \nabla</em>{w} C$, need to specify the Hessian matrix as the <code>hess</code> parameter).</p>
<p><code>maxiter</code> <strong>specifies the maximum number of iterations to perform</strong> and displays a message when the optimization does not converge when <code>maxiter</code> is reached.</p>
<p><code>tol</code> <strong>specifies when the optimization is considered converged</strong>, usually it means either the difference between the function (loss) values between two consecutive iterations is less than <code>tol</code>, or the distance between the argument (weights) is less than <code>tol</code>.</p>
<h3 id="Local-Minima"><a href="#Local-Minima" class="headerlink" title="Local Minima"></a>Local Minima</h3><p>Gradient methods may get stuck at a local minimum, where the gradient at the point is 0, but the point is not the (global) minimum of the function.</p>
<p>Multiple random initial points may be used to find multiple local minima, and they can be compared to find the best one.</p>
<p>If a function is convex, then the only local minimum is the global minimum.</p>
<p>The reason cross-entropy loss is used for logistic regression to measure the error is because the resulting $C\left(w\right)$ is convex and differentiable, thus easy to minimize using gradient methods.</p>
<h2 id="Linear-Programming-线性规划"><a href="#Linear-Programming-线性规划" class="headerlink" title="Linear Programming 线性规划"></a>Linear Programming 线性规划</h2><p>A linear program is <strong>an optimization problem in which the objective is linear and the constraints are linear</strong>.</p>
<p>The set of feasible solutions are the ones that satisfy the constraints, but may or may not be optimal.</p>
<p>The feasible solutions of linear programs form a convex polytope (line segment in 1D, convex polygon in 2D).</p>
<h3 id="Standard-Form"><a href="#Standard-Form" class="headerlink" title="Standard Form"></a>Standard Form</h3><p>The standard form of a linear program is: $ \displaystyle\max_{x} c^\top x$ subject to $A x \leq b$ and $x \geq 0$.<br>For example, if there are two variables and two constraints, then the standard form is: $\displaystyle\max_{x_{1}, x_{2}} c_{1} x_{1} + c_{2} x_{2}$  subject to $A_{21} x_{1} + A_{22} x_{2} \leq b_{2}$ and $x_{1}, x_{2} \geq 0$, which in matrix form, it is $\displaystyle\max_{\begin{bmatrix} x_{1} \ x_{2} \end{bmatrix}} \begin{bmatrix} c_{1} &amp; c_{2} \end{bmatrix} \begin{bmatrix} x_{1} \ x_{2} \end{bmatrix}$ subject to $\begin{bmatrix} A_{11} &amp; A_{12} \ A_{21} &amp; A_{22} \end{bmatrix} \begin{bmatrix} x_{1} \ x_{2} \end{bmatrix} \leq \begin{bmatrix} b_{1} \ b_{2} \end{bmatrix}$ and $\begin{bmatrix} x_{1} \ x_{2} \end{bmatrix} \geq \begin{bmatrix} 0 \ 0 \end{bmatrix}$.</p>
<h3 id="Dual-Form-对偶"><a href="#Dual-Form-对偶" class="headerlink" title="Dual Form 对偶"></a>Dual Form 对偶</h3><p>The dual form of a linear program in standard form is: $\displaystyle\min b^\top y$ subject to $A^\top y \geq c$ and $y \geq 0$.</p>
<p>For example, the dual form of the two variable is, $\displaystyle\min_{y_{1}, y_{2}} b_{1} y_{1} + b_{2} y_{2}$ subject to $A_{12} y_{1} + A_{22} y_{2} \geq c_{2}$, $A_{12} y_{1} + A_{22} y_{2} \geq c_{2}$ and $y_{1}, y_{2} \geq 0$, which in matrix form, it is $\displaystyle\max_{\begin{bmatrix} y_{1} \ y_{2} \end{bmatrix}} \begin{bmatrix} b_{1} &amp; b_{2} \end{bmatrix} \begin{bmatrix} y_{1} \ y_{2} \end{bmatrix}$ subject to $\begin{bmatrix} A_{11} &amp; A_{21} \ A_{12} &amp; A_{22} \end{bmatrix} \begin{bmatrix} y_{1} \ y_{2} \end{bmatrix} \geq \begin{bmatrix} c_{1} \ c_{2} \end{bmatrix}$ and $\begin{bmatrix} y_{1} \ y_{2} \end{bmatrix} \geq \begin{bmatrix} 0 \ 0 \end{bmatrix}$.</p>
<p>Duality theorem says that <strong>the primal and dual solutions lead to the same objective value</strong>.</p>
<h3 id="Application-in-Regression"><a href="#Application-in-Regression" class="headerlink" title="Application in Regression"></a>Application in Regression</h3><p>The problem of regression by minimizing the sum of absolute value of the error (instead of the square), that is, $C\left(w\right) = \displaystyle\min_{w} \displaystyle\sum_{i=1}^{n} \left| y_{i} - \left(w_{1} x_{i1} + w_{2} x_{i2} + … + w_{m} x_{im} + b\right) \right|$, can be written as a linear program.</p>
<p>The can be done by noting $\left| a \right| = \displaystyle\max\left{a, -a\right}$, so the problem can be written as, $\displaystyle\min_{a, w, b} \displaystyle\sum_{i=1}^{n} a_{i}$ subject to $a_{i} \geq y_{i} - \left(w_{1} x_{i1} + w_{2} x_{i2} + … + w_{m} x_{im} + b\right)$ and $a_{i} \geq -\left(y_{i} - \left(w_{1} x_{i1} + w_{2} x_{i2} + … + w_{m} x_{im} + b\right)\right)$.</p>
<p>The resulting regression problem is also called Least Absolute Deviations (LAD)</p>
<h3 id="Application-to-Classification"><a href="#Application-to-Classification" class="headerlink" title="Application to Classification"></a>Application to Classification</h3><p>The problem of finding the optimal weights for a support vector machine can be written as <strong>minimizing the hinge loss</strong> $C\left(w\right) = \displaystyle\sum_{i=1}^{n} \displaystyle\max\left{1 - \left(2 y_{i} - 1\right) \cdot \left(w_{1} x_{i1} + w_{2} x_{i2} + … + w_{m} x_{im} + b\right), 0\right}$, which can be converted into a linear program.</p>
<p>Similar to the regression problem, the problem can be written as, $\displaystyle\min_{a, w, b} \displaystyle\sum_{i=1}^{n} a_{i}$ subject to $a_{i} \geq 1 - \left(w_{1} x_{i1} + w_{2} x_{i2} + … + w_{m} x_{im} + b\right)$ if $y_{i} = 1$, and $a_{i} \geq 1 + \left(w_{1} x_{i1} + w_{2} x_{i2} + … + w_{m} x_{im} + b\right)$ if $y_{i} = 0$, and $a_{i} \geq 0$.</p>
<p>When kernel trick is used, the dual of the linear program with the new features, possibly infinite number of them, is finite and can be solved instead.</p>
<h1 id="Unsupervised-Learning"><a href="#Unsupervised-Learning" class="headerlink" title="Unsupervised Learning"></a>Unsupervised Learning</h1><p>Unsupervised learning (data is unlabeled): use the data to find patterns and put items into groups.</p>
<p>If the groups are discrete: clustering</p>
<p>If the groups are continuous (lower dimensional representation): dimensionality reduction</p>
<h2 id="Hierarchical-Clustering"><a href="#Hierarchical-Clustering" class="headerlink" title="Hierarchical Clustering"></a>Hierarchical Clustering</h2><p>Hierarchical clustering starts with n clusters and iteratively merge the closest clusters</p>
<p>It is also called agglomerative clustering, and can be performed using <code>sklearn.cluster.AgglomerativeClustering</code></p>
<p>Different ways of defining the distance between two clusters are called different linkages: <code>scipy.cluster.hierarchy.linkage</code></p>
<h3 id="Distance-Measure"><a href="#Distance-Measure" class="headerlink" title="Distance Measure"></a>Distance Measure</h3><p>(1) Manhattan distance (<code>metric = &quot;manhattan&quot;</code>): $\left| x_{11} - x_{21} \right| + \left| x_{12} - x_{22} \right| + … + \left| x_{1m} - x_{2m} \right|$,<br>(2) Euclidean distance (<code>metric = &quot;euclidean&quot;</code>): $\sqrt{\left(x_{11} - x_{21}\right)^{2} + \left(x_{12} - x_{22}\right)^{2} + … + \left(x_{1m} - x_{2m}\right)^{2}}$,<br>(3) Cosine similarity distance (<code>metric = &quot;cosine&quot;</code>): $1 - \dfrac{x^\top_{1} x_{2}}{\sqrt{x^\top_{1} x_{1}} \sqrt{x^\top_{2} x_{2}}}$.</p>
<p>If average linkage distance (<code>linkage = &quot;average&quot;</code>) is used, then the distance between two clusters is defined as the <strong>distance between two center points of the clusters</strong>.</p>
<p>This requires recomputing the centers and their pairwise distances in every iteration and can be very slow.</p>
<h3 id="Single-and-Complete-Linkage-Distance"><a href="#Single-and-Complete-Linkage-Distance" class="headerlink" title="Single and Complete Linkage Distance"></a>Single and Complete Linkage Distance</h3><p>If single linkage distance (<code>linkage = &quot;single&quot;</code>) is used, then the distance between two clusters is defined as the <strong>smallest distance between any pairs of points one from each cluster</strong>.</p>
<p>If complete linkage distance (<code>linkage = &quot;complete&quot;</code>) is used, then the distance between two clusters is defined as <strong>the largest distance</strong> between any pairs of points one from each cluster.</p>
<p>With single or complete linkage distances, pairwise distances between points only <strong>have to be computed once at the beginning</strong>, so clustering is typically faster.</p>
<h3 id="Single-vs-Complete-Linkage"><a href="#Single-vs-Complete-Linkage" class="headerlink" title="Single vs Complete Linkage"></a>Single vs Complete Linkage</h3><p>Since single linkage distance finds the nearest neighbors, it is more likely to <strong>have clusters that look like chains in which pairs of points are close to each other</strong>.</p>
<p>Since complete linkage distance finds the farthest neighbors, it is more likely to have clusters that look like blobs (for example circles) <strong>in which all points are closest to a center</strong>.</p>
<p>The choice usually depends on the application. </p>
<h3 id="Number-of-Clusters"><a href="#Number-of-Clusters" class="headerlink" title="Number of Clusters"></a>Number of Clusters</h3><p>The number of clusters are usually chosen based on application requirements, since there is no optimal number of clusters.</p>
<p>If the number of clusters is not specified, the algorithm can output a clustering tree, called dendrogram.</p>
<p><code>scipy.cluster.hierarchy.dendrogram</code></p>
<p>dendrogram is a binary tree</p>
<p><img src="/2023/10/07/CS320学习笔记/27.png" alt></p>
<h2 id="K-Means"><a href="#K-Means" class="headerlink" title="K Means"></a>K Means</h2><p>(0) Start with K random centers (also called centroids) $\mu_{1}, \mu_{2}, …, \mu_{K}$.<br>(1) Assign step: find points (items) that are the closest to each center k, label these points as k.<br>(2) Center step: update center $\mu_{k}$ to be the center of the points labeled k.<br>(3) Repeat until cluster centers do not change.</p>
<h3 id="Total-Distortion"><a href="#Total-Distortion" class="headerlink" title="Total Distortion"></a>Total Distortion</h3><p>The objective of K means clustering is <strong>minimizing the total distortion, also called inertia</strong>, the sum of distances (usually squared Euclidean distances) from the points to their centers, or $\displaystyle\sum_{i=1}^{n} \left|x_{i} - \mu_{k\left(x_{i}\right)}\right|^{2}$, where $k\left(x_{i}\right)$ is the cluster index of the cluster closest to $x_{i}$, or $k\left(x_{i}\right) = \mathop{\mathrm{argmin}}<em>{k} \left|x</em>{i} - \mu_{k}\right|$.</p>
<p>K means initialized at a random clustering and each assign-center step is a gradient descent step for minimizing total distortion by choosing the cluster centers.</p>
<h3 id="Number-of-Clusters-1"><a href="#Number-of-Clusters-1" class="headerlink" title="Number of Clusters"></a>Number of Clusters</h3><p>The number of clusters are usually chosen based on application requirements, since there is no optimal number of clusters.</p>
<p>If the number of cluster is n (each point is in a different cluster), then the total distortion is 0. This means minimizing the total distortion is not a good way to select the number of clusters.</p>
<p>Elbow method is sometimes use to determine the number of clusters based on the total distortion, but it is a not a clearly defined algorithm</p>
<p><strong>small inertia and few clusters</strong></p>
<h2 id="Dimensionality-Reduction"><a href="#Dimensionality-Reduction" class="headerlink" title="Dimensionality Reduction"></a>Dimensionality Reduction</h2><p>Dimensionality reduction finds a low dimensional representation of a high dimensional point (item) in a way that points that close to each other in the original space are close to each other in the low dimensional space.</p>
<p>Text and image data have a large number of features (dimensions), dimensionality reduction techniques can be used for <strong>visualization and efficient storage of these data types</strong></p>
<h3 id="PCA-Principal-Component-Analysis"><a href="#PCA-Principal-Component-Analysis" class="headerlink" title="PCA (Principal Component Analysis)"></a>PCA (Principal Component Analysis)</h3><p>Principal component analysis finds the orthogonal directions that capture the highest variation, called principal components, and project the feature vectors onto the subspace generated by the principal components.</p>
<h3 id="Projected-Variances"><a href="#Projected-Variances" class="headerlink" title="Projected Variances"></a>Projected Variances</h3><p>Projected variance along a direction u is can be computed by $u^\top \Sigma u$, so the PCA problem is given by the constrained optimization problem $\displaystyle\max_{u} u^\top \Sigma u$ subject to $u^\top u = 1$.</p>
<p>A closed-form solution is $\Sigma u = \lambda u$, which means $\lambda$ is an eigenvalue of $\Sigma$ and u is an eigenvector of $\Sigma$.</p>
<p>A faster way to find the eigenvalue-eigenvector pair is through singular value decomposition (SVD), and it is used in <code>sklearn.decomposition.PCA</code></p>
<h3 id="Reconstruction"><a href="#Reconstruction" class="headerlink" title="Reconstruction"></a>Reconstruction</h3><p>If there are m original features, and m principal components are computed, then the original item can be perfectly reconstructed, if only $k&lt;m$ principal components are used, then the original item can be approximated.</p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Length</th>
<th>Formula</th>
<th>Note</th>
</tr>
</thead>
<tbody>
<tr>
<td>Original</td>
<td>m</td>
<td>$x = \begin{bmatrix} x_{i 1} \ x_{i 2} \ … \ x_{i m} \end{bmatrix}$</td>
<td>-</td>
</tr>
<tr>
<td>PCA Features</td>
<td>k</td>
<td>$x’ = \begin{bmatrix} u^\top_{1} x \ u^\top_{2} x \ … \ u^\top_{k} x \end{bmatrix}$</td>
<td>$u_{1}, u_{2}, …$are principal components</td>
</tr>
<tr>
<td>Reconstruction</td>
<td>m</td>
<td>$x = x’<em>{1} u</em>{1} + x’<em>{2} u</em>{2} + … + x’<em>{m} u</em>{m}$</td>
<td>Equal to original x</td>
</tr>
<tr>
<td>Approximation</td>
<td>m</td>
<td>$\hat{x} = x’<em>{1} u</em>{1} + x’<em>{2} u</em>{2} + … + x’<em>{k} u</em>{k} \approx x$</td>
<td>Length m, not k</td>
</tr>
</tbody>
</table>
<h3 id="Number-of-Reduced-Dimensions"><a href="#Number-of-Reduced-Dimensions" class="headerlink" title="Number of Reduced Dimensions"></a>Number of Reduced Dimensions</h3><p>Similar to other clustering methods, the number of dimensions K are usually chosen based on application requirements (for example, 2 or 3 for visualization).</p>
<p><code>sklearn.decomposition.PCA(k)</code> can take in <code>k</code> values between 0 and 1 too, and in that case, <code>k</code> represents the target amount of variance that needs to be explained, k for rows, colunms 不变</p>
<p>Auto-Encoder<br>If a neural network is trained with y=x, then the hidden layer unit values can be viewed as “encoding” of x.</p>
<p>Auto-encoder is a non-linear dimensionality reduction method if the neural network has nonlinear activations.</p>
<h1 id="Reproducibility-1"><a href="#Reproducibility-1" class="headerlink" title="Reproducibility"></a>Reproducibility</h1><h2 id="Pseudorandom-Numbers"><a href="#Pseudorandom-Numbers" class="headerlink" title="Pseudorandom Numbers"></a>Pseudorandom Numbers</h2><p>A random sequence can be generated by a recurrence relation, for example, $x_{t+1} = \left(a x_{t} + c\right) \mod m$.</p>
<p>$x_0$ is called the seed, and if a,c,m are large and unknown, then the sequence looks random.</p>
<p><code>numpy.random</code> uses a more complicated PCG generator, but with a similar deterministic sequence that looks random</p>
<h2 id="Discrete-Distributions"><a href="#Discrete-Distributions" class="headerlink" title="Discrete Distributions"></a>Discrete Distributions</h2><p>A discrete distribution takes on finite or countably infinite number of values (for example, 0, 1, 2, …).</p>
<p>The distribution can be summarized in a table containing the probability that it takes on each value, for example $\mathbb{P}\left{X = a\right}, a = 0, 1, 2, …$</p>
<p>The probabilities should be non-negative and sum up to one.</p>
<h2 id="Continuous-Distributions"><a href="#Continuous-Distributions" class="headerlink" title="Continuous Distributions"></a>Continuous Distributions</h2><p>A continuous distribution takes on uncountably infinite number of values (for example, real numbers between 0 and 1).</p>
<p>The distribution can be summarized as a probability density function $f\left(x\right)$ with the property that $\mathbb{P}\left{a \leq X \leq b\right} = \displaystyle\int_{a}^{b} f\left(x\right) dx$</p>
<p>The density function should be non-negative and integrates to 1.</p>
<p>For a continuous $\mathbb{P}\left{X = x\right} = 0$ always has 0 probability of taking on any specific value.</p>
<p>Ex:<code>multivariate_normal([0, 0], [[1, 2], [2, 4]], 1000)</code></p>
<p>第一个矩阵表示[x_mean,y_mean]</p>
<p>第二个表示$\left( \begin{bmatrix} \sigma_{X}^{2} &amp; c_{X Y} \ c_{YX} &amp; \sigma_{Y}^{2} \end{bmatrix} \right)$</p>
<p>左上角是$\sigma_{X}^{2}$</p>
<p>correlation=$\rho_{X Y} = \dfrac{c_{X Y}}{\sigma_{X} \sigma_{Y}} = \dfrac{2}{1 \cdot 2} = 1$</p>
<h2 id="Markov-Chain"><a href="#Markov-Chain" class="headerlink" title="Markov Chain"></a>Markov Chain</h2><h3 id="Stochastic-Processes"><a href="#Stochastic-Processes" class="headerlink" title="Stochastic Processes"></a>Stochastic Processes</h3><p>A stochastic process is a sequence of random variables.</p>
<p>If the sequence is finite or countably infinite, it is called a discrete-time stochastic process, and the index represent the time step, usually, 0,1,….</p>
<p>If the sequence is uncountably infinite, it is a continuous-time stochastic process.</p>
<h2 id="Markov-Chains"><a href="#Markov-Chains" class="headerlink" title="Markov Chains"></a>Markov Chains</h2><p>One special class of stochastic processes is called Markov processes, where $X_t$ only depends on $X_{t-1}$, but not $X_{t-2}, X_{t-3}, …$</p>
<p>Formally, the sequence $X_t$ is a (discrete-time) Markov chain, $\mathbb{P}\left{X_{t} = x | X_{1} = x_{1}, X_{2} = x_{2}, …, X_{t-1} = x_{t-1}\right}$</p>
<h3 id="Transition-Matrices"><a href="#Transition-Matrices" class="headerlink" title="Transition Matrices"></a>Transition Matrices</h3><p>If the time $t$ and the state distribution $X_t$are both discrete, a Markov chain can be represented by a transition matrix.</p>
<p>A transition matrix is a matrix where row i column j represents the probability that $\mathbb{P}\left{X_{t} = j | X_{t-1} = i\right}$</p>
<table>
<thead>
<tr>
<th>From \ to</th>
<th>1</th>
<th>2</th>
<th>3</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>$\mathbb{P}\left{X_{t} = 1</td>
<td>X_{t-1} = 1\right}$</td>
<td>$\mathbb{P}\left{X_{t} = 2</td>
<td>X_{t-1} = 1\right}$</td>
<td>$\mathbb{P}\left{X_{t} = 3</td>
<td>X_{t-1} = 1\right}$</td>
</tr>
<tr>
<td>2</td>
<td>$\mathbb{P}\left{X_{t} = 1</td>
<td>X_{t-1} = 2\right}$</td>
<td>$\mathbb{P}\left{X_{t} = 2</td>
<td>X_{t-1} = 2\right}$</td>
<td>$\mathbb{P}\left{X_{t} = 3</td>
<td>X_{t-1} = 1\right}$</td>
</tr>
<tr>
<td>3</td>
<td>$\mathbb{P}\left{X_{t} = 1</td>
<td>X_{t-1} = 3\right}$</td>
<td>$\mathbb{P}\left{X_{t} = 2</td>
<td>X_{t-1} = 3\right}$</td>
<td>$\mathbb{P}\left{X_{t} = 3</td>
<td>X_{t-1} = 1\right}$</td>
</tr>
</tbody>
</table>
<p>The rows of transition matrices should sum up to 1. The columns does not have to sum up to 1.</p>
<p>One simple language model is the bigram model, which estimates and simulates the distribution of the next word given the current word.</p>
<h3 id="Simulation-and-Estimation"><a href="#Simulation-and-Estimation" class="headerlink" title="Simulation and Estimation"></a>Simulation and Estimation</h3><p>To simulate a Markov chain with transition matrix <code>m</code> starting from state <code>x0</code> from 0, 1, 2, …: use <code>x1 = numpy.random.choice(len(m), p = m[x0, :])</code>, and <code>x2 = numpy.random.choice(len(m), p = m[x1, :])</code>, and so on</p>
<p>To estimate a Markov chain transition matrix given a sequence, one way is to use the maximum likelihood estimate: $\hat{\mathbb{P}}\left{X_{t} = j | X_{t-1} = i\right} = \dfrac{c_{i j}}{c_{i}}$, where $c_{ij}$ is the number of times i is followed by j in the sequence, and $c_i$ is the number of times i appears in the sequence.</p>

            </div>

            <!-- Post Comments -->
            
    <!-- 使用 valine -->
<div id="comment">
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
<script>
    new Valine({
        el: '#comment' ,
        notify: false,
        verify: false,
        app_id: 'fUtpOauFo2JhcWoBFEnnppJW-gzGzoHsz',
        app_key: 'gFTwG42ACHuyrmwhMfgxcRQQ',
        placeholder: '留下你的评论吧~~',
        pageSize: '10',
        avatar: '',
        avatar_cdn: 'https://gravatar.loli.net/avatar/'
    });
</script>
</div>
<style>
   #comment{
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
                <li>Design: <a href="http://miccall.tech " style="border-bottom: none;">miccall</a></li>
            </ul>
            
            	<span id="busuanzi_container_site_pv">2024总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			
        </div>
    </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"left","width":125,"height":250},"mobile":{"show":false},"log":false});</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"left","width":125,"height":250},"mobile":{"show":false},"log":false});</script></body>




 	

    
</html>
